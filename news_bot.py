import os, json, time, resend
from google import genai
from gnews import GNews
from supabase import create_client, Client
from datetime import datetime
from difflib import SequenceMatcher

# í™˜ê²½ ì„¤ì •
GEMINI_KEY = os.environ.get("GEMINI_API_KEY")
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")
resend.api_key = os.environ.get("RESEND_API_KEY")

TODAY = datetime.now().strftime("%Y-%m-%d")

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
google_genai = genai.Client(api_key=GEMINI_KEY)
# ìœ ì‚¬ë„ í•„í„°ë§ì„ ìœ„í•´ 10ê°œë¥¼ ê°€ì ¸ì™€ 5ê°œë¥¼ ì„ íƒ
google_news = GNews(language='ko', country='KR', period='2d', max_results=10)

def is_similar(a, b):
    return SequenceMatcher(None, a, b).ratio()

def analyze_news(title, role="PM"):
    prompt = f"ë‹¹ì‹ ì€ {role}ì…ë‹ˆë‹¤. ë‰´ìŠ¤ '{title}'ì„ 3ê°œ ë¶ˆë¦¿ í¬ì¸íŠ¸ë¡œ ìš”ì•½í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ì£¼ì‹­ì‹œì˜¤."
    try:
        res = google_genai.models.generate_content(model="gemini-2.0-flash", contents=prompt)
        return res.text
    except: return "â€¢ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"

# [V5.6 ë¡œì§] ëª¨ë“  ì‚¬ìš©ì ë¦¬í¬íŠ¸ ê°œë³„ ìƒì„±
users_res = supabase.table("users").select("*").execute()
users = users_res.data

print(f"ğŸ“¡ ì´ {len(users)}ëª…ì˜ ì‚¬ìš©ìë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")

for user in users:
    user_id = user['id']
    user_email = user['email']
    
    kw_res = supabase.table("keywords").select("word").eq("user_id", user_id).eq("is_active", True).execute()
    user_keywords = [k['word'] for k in kw_res.data][:5] # í‚¤ì›Œë“œ 5ê°œ ì œí•œ
    
    if not user_keywords: continue

    print(f"ğŸ” {user_email}ë‹˜(í‚¤ì›Œë“œ: {user_keywords}) ë¶„ì„ ì¤‘...")
    
    # [í•µì‹¬] ìœ ì €ë³„ ë…ë¦½ ë¦¬í¬íŠ¸ ê°ì²´ ìƒì„±
    user_report = {"date": TODAY, "articles": [], "pm_brief": "", "ba_brief": "", "securities_brief": "", "tracked_keywords": user_keywords}
    all_titles = []

    for word in user_keywords:
        news_items = google_news.get_news(word)
        unique_news = []
        for news in news_items:
            if any(is_similar(news['title'], u['title']) > 0.6 for u in unique_news): continue
            unique_news.append(news)
            if len(unique_news) >= 5: break # í‚¤ì›Œë“œë‹¹ 5ê°œ ì œí•œ

        for news in unique_news:
            pm_sum = analyze_news(news['title'], "PM")
            ba_sum = analyze_news(news['title'], "BA")
            # ì¦ê¶Œ ì—ì´ì „íŠ¸ ì¶”ê°€
            sec_sum = analyze_news(news['title'], "ì¦ê¶Œ ë¶„ì„ê°€")
            
            article = {"keyword": word, "title": news['title'], "url": news['url'], "pm_summary": pm_sum, "ba_summary": ba_sum, "sec_summary": sec_sum}
            user_report["articles"].append(article)
            all_titles.append(f"[{word}] {news['title']}")
            time.sleep(1)

    # [í•µì‹¬] ìœ ì €ë³„ ë¦¬í¬íŠ¸ DB ì €ì¥ (ë§ˆìŠ¤í„° ì œí•œ í•´ì œ)
    if user_report["articles"]:
        titles_combined = "\n".join(all_titles)
        user_report["pm_brief"] = analyze_news(f"ì¢…í•© ìš”ì•½:\n{titles_combined}", "PM")
        user_report["ba_brief"] = analyze_news(f"ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„:\n{titles_combined}", "BA")
        user_report["securities_brief"] = analyze_news(f"ì¦ê¶Œ ì‹œì¥ ë¶„ì„:\n{titles_combined}", "ì¦ê¶Œ ë¶„ì„ê°€")
        
        supabase.table("reports").insert({
            "user_id": user_id,
            "report_date": TODAY,
            "content": user_report
        }).execute()
        print(f"âœ… {user_email}ë‹˜ì˜ ë¦¬í¬íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
