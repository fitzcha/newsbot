# ê°œì„  ì œì•ˆ 1: ë‰´ìŠ¤ ì»¨í…ìŠ¤íŠ¸ ì œê³µ ë°©ì‹ ê°œì„ 

# Situation: í˜„ì¬ ë‰´ìŠ¤ ì»¨í…ìŠ¤íŠ¸ ì œê³µ ì‹œ, ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ë‹¨ìˆœ ë‚˜ì—´í•˜ì—¬ ì •ë³´ íŒŒì•… ë° ì‹ ë¢°ë„ íŒë‹¨ì´ ì–´ë ¤ì›€.
# Behavior: ê° ë‰´ìŠ¤ ê¸°ì‚¬ë³„ í•µì‹¬ ë‚´ìš© ìš”ì•½ ë° ê¸/ë¶€ì • ê°ì„± ë¶„ì„, ì–¸ë¡ ì‚¬ í‰íŒ ë“± ì¶œì²˜ ì‹ ë¢°ë„ ì •ë³´ë¥¼ í•¨ê»˜ ì œê³µ.
# Impact: ì‚¬ìš©ì ì •ë³´ ì‹ ë¢°ë„ íŒë‹¨ ë° ë§¥ë½ íŒŒì•… ì‹œê°„ ë‹¨ì¶•, ì •ë³´ í™œìš©ë„ í–¥ìƒ.

def improve_news_context(news_list):
    """ë‰´ìŠ¤ ëª©ë¡ì„ ë°›ì•„ í•µì‹¬ ë‚´ìš© ìš”ì•½, ê°ì„± ë¶„ì„, ì‹ ë¢°ë„ ì •ë³´ë¥¼ ì¶”ê°€í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    # 1. (ê°€ì •) ë‰´ìŠ¤ ê¸°ì‚¬ ì œëª©, ë‚´ìš©, ì–¸ë¡ ì‚¬ ì •ë³´ë¥¼ ë‹´ì€ news_list ë¥¼ ì…ë ¥ ë°›ìŒ
    # 2. ê° ê¸°ì‚¬ë³„ ìš”ì•½ ë° ê°ì„± ë¶„ì„ ìˆ˜í–‰ (Gemini API í™œìš©)
    # 3. ì–¸ë¡ ì‚¬ í‰íŒ ì ìˆ˜ ë°˜ì˜ (ë³„ë„ DB ë˜ëŠ” API í™œìš©)
    # 4. ìµœì¢… ê²°ê³¼ ë°˜í™˜
    
    updated_news_list = []
    for news in news_list:
        summary = call_agent(f"ë‰´ìŠ¤ ìš”ì•½: {news['title']} ë‚´ìš©: {news['content']}", agents['NEWS_SUMMARY'], force_one_line=True)
        sentiment = call_agent(f"ë‰´ìŠ¤ ê°ì„± ë¶„ì„: {news['title']} ë‚´ìš©: {news['content']}", agents['SENTIMENT_ANALYSIS'], force_one_line=True)
        trust_score = get_publisher_trust_score(news['publisher']) # ê°€ì •: ì–¸ë¡ ì‚¬ ì‹ ë¢°ë„ ì ìˆ˜ ë°˜í™˜ í•¨ìˆ˜
        updated_news = {
            **news,
            "summary": summary,
            "sentiment": sentiment,
            "trust_score": trust_score
        }
        updated_news_list.append(updated_news)
    return updated_news_list

def get_publisher_trust_score(publisher):
    """ì–¸ë¡ ì‚¬ ì´ë¦„ì„ ë°›ì•„ ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤ (ê°€ì •)."""
    # DB ë˜ëŠ” API ì—°ë™í•˜ì—¬ ì–¸ë¡ ì‚¬ ì‹ ë¢°ë„ ì ìˆ˜ ë°˜í™˜ ë¡œì§ êµ¬í˜„
    # ì˜ˆì‹œ: ì‹ ë¢°ë„ ì ìˆ˜ëŠ” 0~100 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ í‘œí˜„
    if publisher == "ì—°í•©ë‰´ìŠ¤":
        return 90
    elif publisher == "ì¡°ì„ ì¼ë³´":
        return 60
    else:
        return 70

def run_autonomous_engine():
    agents = get_agents()
    print(f"ğŸš€ {TODAY} Sovereign Engine v17.5 ê°€ë™")

    user_res = supabase.table("user_settings").select("*").execute()
    for user in (user_res.data or []):
        try:
            user_id    = user['id']
            user_email = user.get('email', 'Unknown')
            keywords   = user.get('keywords', [])[:5]
            if not keywords: continue

            chk = supabase.table("reports").select("id, email_sent").eq("user_id", user_id).eq("report_date", TODAY).execute()
            if chk.data and chk.data[0].get("email_sent"):
                print(f"â­ï¸  [Skip] {user_email} â€” ì´ë¯¸ ë°œì†¡ ì™„ë£Œ")
                continue

            print(f"ğŸ” [{user_email}] í‚¤ì›Œë“œ {keywords} ë¶„ì„ ì‹œì‘")

            by_keyword   = {}
            all_articles = []
            all_yt       = []

            for word in keywords:
                print(f"  ğŸ“° [{word}] ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
                is_korean = any(ord(c) > 0x1100 for c in word)
                gn        = GNews(language='ko' if is_korean else 'en', max_results=10)
                news_list = gn.get_news(word)

                record_performance(user_id, word, len(news_list))

                if not news_list:
                    print(f"  âš ï¸  [{word}] ë‰´ìŠ¤ ì—†ìŒ â€” ìŠ¤í‚µ")
                    by_keyword[word] = {
                        "ba_brief":         {"summary": "í•´ë‹¹ í‚¤ì›Œë“œì˜ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "points": [], "deep": []},
                        "securities_brief": {"summary": "í•´ë‹¹ í‚¤ì›Œë“œì˜ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "points": [], "deep": []},
                        "pm_brief":         {"summary": "í•´ë‹¹ í‚¤ì›Œë“œì˜ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "points": [], "deep": []},
                        "articles":         []
                    }
                    continue

                # ê°œì„ : ë‰´ìŠ¤ ì»¨í…ìŠ¤íŠ¸ ì œê³µ ë°©ì‹ ê°œì„  ì ìš©
                articles = []
                kw_ctx   = []
                
                # ê¸°ì¡´ ì½”ë“œ ì£¼ì„ ì²˜ë¦¬ ë˜ëŠ” ì œê±°
                # for n in news_list:
                #     pm_summary = call_agent(f"ë‰´ìŠ¤: {n['title']}", agents['BRIEF'], force_one_line=True)
                #     impact     = call_agent(
                #         f"ë‰´ìŠ¤: {n['title']}\nì „ë§ 1ì¤„.",
                #         agents.get('STOCK', agents['BRIEF']),
                #         force_one_line=True
                #     )
                #     articles.append({**n, "keyword": word, "pm_summary": pm_summary, "impact": impact})
                #     kw_ctx.append(n['title'])
                #     all_articles.append(f"[{word}] {n['title']}")
                
                updated_news_list = improve_news_context(news_list) # ê°œì„ ëœ í•¨ìˆ˜ í˜¸ì¶œ
                
                # ì—…ë°ì´íŠ¸ ëœ ë‰´ìŠ¤ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ articles ë° kw_ctx ìƒì„±
                for n in updated_news_list:
                    articles.append({**n, "keyword": word})
                    kw_ctx.append(n['title'])
                    all_articles.append(f"[{word}] {n['title']}")
                    
                print(f"  ğŸ¬ [{word}] YouTube ìˆ˜ì§‘ ì¤‘...")
                yt_videos = get_youtube_with_cache(word)
                all_yt.extend(yt_videos)
                yt_ctx = build_youtube_context(yt_videos)

                ctx = "\n".join(kw_ctx)
                if yt_ctx:
                    ctx += f"\n\n{yt_ctx}"

                print(f"  ğŸ¤– [{word}] ì—ì´ì „íŠ¸ ë¶„ì„ ì¤‘...")
                by_keyword[word] = {
                    "ba_brief": call_agent_json(
                        f"í‚¤ì›Œë“œ '{word}' ë‰´ìŠ¤ ë° ìœ íŠœë¸Œ ê¸°ë°˜ ë¹„ì¦ˆë‹ˆìŠ¤ ìˆ˜ìµ êµ¬ì¡° ë° ê²½ìŸ ë¶„ì„:\n{ctx}",
                        agents['BA']
                    ),
                    "securities_brief": call_agent_json(
                        f"í‚¤ì›Œë“œ '{word}' ë‰´ìŠ¤ ë° ìœ íŠœë¸Œ ê¸°ë°˜ ì£¼ì‹ ì‹œì¥ ë°˜ì‘ ë° íˆ¬ì ì¸ì‚¬ì´íŠ¸:\n{ctx}",
                        agents['STOCK']
                    ),
                    "pm_brief": call_agent_json(
                        f"í‚¤ì›Œë“œ '{word}' ë‰´ìŠ¤ ë° ìœ íŠœë¸Œ ê¸°ë°˜ ì „ëµì  ì„œë¹„ìŠ¤ ê¸°íš ë¸Œë¦¬í•‘:\n{ctx}",
                        agents['PM']
                    ),
                    "articles":       articles,
                    "youtube_videos": yt_videos,
                }

            if not by_keyword:
                print(f"âš ï¸  [{user_email}] ë¶„ì„ ê²°ê³¼ ì—†ìŒ â€” ìŠ¤í‚µ")
                continue

            all_ctx     = "\n".join(all_articles)
            hr_proposal = call_agent(
                f"ì¡°ì§ ë° ì¸ì‚¬ ê´€ë¦¬ ì œì•ˆ (ì „ì²´ í‚¤ì›Œë“œ ê¸°ë°˜):\n{all_ctx}",
                agents['HR']
            )

            final_report = {
                "by_keyword":  by_keyword,
                "hr_proposal": hr_proposal,
            }

            res = supabase.table("reports").upsert({
                "user_id":     user_id,
                "report_date": TODAY,
                "content":     final_report,
                "qa_score":    95
            }, on_conflict="user_id,report_date").execute()

            if res.data:
                report_id = res.data[0]['id']
                run_agent_self_reflection(report_id)
                send_email_report(user_email, final_report, all_yt)
                try:
                    supabase.table("reports").update({"email_sent": True})\
                        .eq("id", report_id).execute()
                except Exception as e:
                    print(f"  âš ï¸ [Email] email_sent ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                print(f"âœ… [{user_email}] ë¦¬í¬íŠ¸ ì €ì¥ ë° ì´ë©”ì¼ ë°œì†¡ ì™„ë£Œ (YouTube {len(all_yt)}ê°œ í¬í•¨)")

        except Exception as e:
            print(f"âŒ ìœ ì € ì—ëŸ¬ ({user_email}): {e}")
            continue

    record_supabase_stats()
    sync_data_to_github()
    run_agent_initiative(by_keyword_all=_collect_all_by_keyword(user_res.data or []))