import os, json, time
from google import genai
from gnews import GNews
from supabase import create_client, Client
from datetime import datetime

# 1. í™˜ê²½ ì„¤ì • (GitHub Secretsì— SUPABASE_URL, SUPABASE_KEY ì¶”ê°€ í•„ìš”)
GEMINI_KEY = os.environ.get("GEMINI_API_KEY")
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")
MASTER_EMAIL = "positivecha@gmail.com"
TODAY = datetime.now().strftime("%Y-%m-%d")

# 2. í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
google_genai = genai.Client(api_key=GEMINI_KEY)
google_news = GNews(language='ko', country='KR', period='2d', max_results=2)

def analyze_news(title, role="PM"):
    """v3.5ì—ì„œ ì •ë¦½í•œ ë¶ˆë¦¿ í¬ì¸íŠ¸ ê¸°ë°˜ ìŠ¤ìºë‹ ìµœì í™” ë¶„ì„"""
    role_desc = "ëª¨ë¹Œë¦¬í‹° PM" if role == "PM" else "ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ê°€"
    prompt = f"ë‹¹ì‹ ì€ {role_desc}ì…ë‹ˆë‹¤. ë‰´ìŠ¤ '{title}'ì„ 3~5ê°œ ë¶ˆë¦¿ í¬ì¸íŠ¸ë¡œ ìš”ì•½í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ì£¼ì‹­ì‹œì˜¤. ë‹¨ë¬¸ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
    try:
        res = google_genai.models.generate_content(model="gemini-2.0-flash", contents=prompt)
        return res.text
    except: return "â€¢ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"

# 3. ëª¨ë“  ìœ ì € ì„¤ì • ë¡œë“œ
def get_all_users():
    # user_settings í…Œì´ë¸”ì—ì„œ ëª¨ë“  ìœ ì €ì˜ ID, ì´ë©”ì¼, í‚¤ì›Œë“œë¥¼ ê°€ì ¸ì˜´
    response = supabase.table("user_settings").select("*").execute()
    return response.data

# 4. ì‹¤í–‰ ë©”ì¸ ë¡œì§
users = get_all_users()
master_report = {"date": TODAY, "articles": [], "pm_brief": "", "ba_brief": "", "tracked_keywords": []}

print(f"ğŸš€ ì´ {len(users)}ëª…ì˜ ìœ ì € ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

for user in users:
    user_email = user.get('email', 'Unknown')
    user_keywords = user.get('keywords', [])
    print(f"--- [{user_email}]ë‹˜ì˜ í‚¤ì›Œë“œ {len(user_keywords)}ê°œ ë¶„ì„ ì¤‘ ---")
    
    user_articles = []
    
    for word in user_keywords:
        news_items = google_news.get_news(word)
        for news in news_items:
            pm_sum = analyze_news(news['title'], "PM")
            ba_sum = analyze_news(news['title'], "BA")
            
            article_data = {
                "keyword": word,
                "title": news['title'],
                "url": news['url'],
                "pm_summary": pm_sum,
                "ba_summary": ba_sum
            }
            user_articles.append(article_data)
            
            # ë§ˆìŠ¤í„°(ì„±í™˜ë‹˜) ë°ì´í„°ëŠ” ê³µìš© ëŒ€ì‹œë³´ë“œ(data.json)ë¥¼ ìœ„í•´ ë³„ë„ ì €ì¥
            if user_email == MASTER_EMAIL:
                master_report["articles"].append(article_data)
                if word not in master_report["tracked_keywords"]:
                    master_report["tracked_keywords"].append(word)

    # TODO: ì—¬ê¸°ì„œ ê°œë³„ ë‰´ìŠ¤ë ˆí„° ë°œì†¡ í•¨ìˆ˜(send_email)ë¥¼ í˜¸ì¶œí•  ì˜ˆì •ì…ë‹ˆë‹¤.
    print(f"âœ… {user_email}ë‹˜ ë¶„ì„ ì™„ë£Œ (ê¸°ì‚¬ {len(user_articles)}ê±´)")

# 5. ë§ˆìŠ¤í„° ë¦¬í¬íŠ¸(ê³µê°œìš©) ì €ì¥
if master_report["articles"]:
    # ì¢…í•© ë¸Œë¦¬í•‘ ìƒì„± ìƒëµ(ê¸°ì¡´ ë¡œì§ ë™ì¼) í›„ data.json ì €ì¥
    file_path = "data.json"
    try:
        with open(file_path, "r", encoding="utf-8") as f: full_data = json.load(f)
    except: full_data = []
    
    full_data = [d for d in full_data if d['date'] != TODAY]
    full_data.insert(0, master_report)
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(full_data, f, ensure_ascii=False, indent=2)

print("ğŸ ëª¨ë“  ìœ ì € ë¶„ì„ ë° ë§ˆìŠ¤í„° ë¦¬í¬íŠ¸ ê°±ì‹  ì™„ë£Œ!")
