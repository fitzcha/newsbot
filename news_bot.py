#!/usr/bin/env python3
import os, json, time, re, subprocess, shutil, urllib.request, urllib.parse
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from google import genai
from gnews import GNews
from supabase import create_client, Client
from datetime import datetime, timedelta, timezone

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê¸°ë³¸ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
KST   = timezone(timedelta(hours=9))
NOW   = datetime.now(KST)
TODAY = NOW.strftime("%Y-%m-%d")

GEMINI_KEY  = os.environ.get("GEMINI_API_KEY")
SB_URL      = os.environ.get("SUPABASE_URL")
SB_KEY      = os.environ.get("SUPABASE_KEY")
YOUTUBE_KEY = os.environ.get("YOUTUBE_API_KEY")

GMAIL_USER = "fitzintelligence@gmail.com"
GMAIL_PASS = os.environ.get("GMAIL_APP_PASSWORD")
CURRENT_BACKLOG_ID = (os.environ.get("CURRENT_BACKLOG_ID") or "").strip()

supabase: Client = create_client(SB_URL, SB_KEY)
google_genai     = genai.Client(api_key=GEMINI_KEY)

DASHBOARD_URL = "https://newsbot-smoky.vercel.app/app.html"

YT_SEARCH_URL  = "https://www.googleapis.com/youtube/v3/search"
YT_VIDEO_URL   = "https://www.googleapis.com/youtube/v3/videos"
YT_CHANNEL_URL = "https://www.googleapis.com/youtube/v3/channels"

EXPERT_SUBSCRIBER_THRESHOLD = 100_000

_GEMINI_PRICE = {
    "gemini-1.5-flash": {"input": 0.000075, "output": 0.000300},
    "gemini-1.5-pro":   {"input": 0.001250, "output": 0.005000},
    "gemini-2.0-flash": {"input": 0.000100, "output": 0.000400},
}
_DEFAULT_MODEL = "gemini-2.0-flash"

_MONITOR_TABLES = [
    "action_logs", "reports", "cost_log", "keyword_performance",
    "pending_approvals", "dev_backlog", "agents",
]

_PROTECTED_ROLES = {"BRIEF", "HR", "MASTER", "DEV", "QA"}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë§ˆí¬ë‹¤ìš´ ì™„ì „ ì œê±° ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def strip_markdown(text: str) -> str:
    """
    Gemini ì¶œë ¥ì—ì„œ ìœ ì €ì—ê²Œ ë…¸ì¶œë˜ë©´ ì•ˆ ë˜ëŠ” ë§ˆí¬ë‹¤ìš´/ë ˆì´ë¸”ì„ ì œê±°í•œë‹¤.
    - **êµµê²Œ**, *ê¸°ìš¸ì„* ì œê±°
    - **ìƒí™©:**, **Situation:**, **BEHAVIOR:**, **IMPACT:**, **ì œì•ˆ:** ë“± ë ˆì´ë¸” ì¤„ ì œê±°
    - ë²ˆí˜¸ ëª©ë¡(1. 2. 3.) â†’ ë‚´ìš©ë§Œ ìœ ì§€
    - ë¶ˆí•„ìš”í•œ ë¹ˆ ì¤„ ì •ë¦¬
    """
    # ë³¼ë“œ/ì´íƒ¤ë¦­ ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì œê±° (* ** ***)
    text = re.sub(r'\*{1,3}', '', text)
    # í—¤ë”(## ì œëª©) ì œê±°
    text = re.sub(r'^#{1,6}\s+', '', text, flags=re.MULTILINE)
    # ë²ˆí˜¸ ëª©ë¡ ê¸°í˜¸ ì œê±° (1. 2. ë“±)
    text = re.sub(r'^\d+\.\s+', '', text, flags=re.MULTILINE)
    # ê¸€ë¨¸ë¦¬ ê¸°í˜¸ ì œê±° (- * â€¢)
    text = re.sub(r'^[\-\*â€¢]\s+', '', text, flags=re.MULTILINE)

    lines = text.splitlines()
    clean = []
    for line in lines:
        stripped = line.strip()
        # "ë ˆì´ë¸”:" íŒ¨í„´ë§Œìœ¼ë¡œ ì´ë£¨ì–´ì§„ ì¤„ ì œê±°
        # ì˜ˆ: "ìƒí™©:", "Situation:", "BEHAVIOR:", "IMPACT:", "ì œì•ˆ:", "í˜„í™©:"
        if re.match(r'^[A-Za-zê°€-í£\sÂ·\-_]+:\s*$', stripped):
            continue
        # ë¹ˆ ì¤„ ì—°ì† 2ê°œ ì´ìƒ â†’ 1ê°œë¡œ
        if stripped == '' and clean and clean[-1] == '':
            continue
        clean.append(stripped)

    return '\n'.join(clean).strip()


def clean_role_name(s: str) -> str:
    """Geminiê°€ ì—­í• ëª…ì— ë¶™ì¸ ** ë“± ë§ˆí¬ë‹¤ìš´ ì œê±°"""
    return re.sub(r'\*+', '', s).strip()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í™˜ê²½ë³€ìˆ˜ ì²´í¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _check_env():
    missing = []
    critical_missing = []
    
    checks = [
        ("GEMINI_API_KEY",     GEMINI_KEY,  True),   # ì¹˜ëª…ì 
        ("SUPABASE_URL",       SB_URL,      True),   # ì¹˜ëª…ì 
        ("SUPABASE_KEY",       SB_KEY,      True),   # ì¹˜ëª…ì 
        ("GMAIL_APP_PASSWORD", GMAIL_PASS,  False),  # ê²½ê³ ë§Œ
        ("YOUTUBE_API_KEY",    YOUTUBE_KEY, False),  # ê²½ê³ ë§Œ
    ]
    
    for key, val, is_critical in checks:
        if not val:
            missing.append(key)
            if is_critical:
                critical_missing.append(key)
    
    if critical_missing:
        error_msg = f"ğŸš¨ [ENV] ì¹˜ëª…ì  í™˜ê²½ë³€ìˆ˜ ëˆ„ë½: {', '.join(critical_missing)}"
        print(error_msg)
        print("âŒ ì‹œìŠ¤í…œì„ ì•ˆì „í•˜ê²Œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        raise EnvironmentError(error_msg)
    
    if missing:
        print(f"âš ï¸  [ENV] ì„ íƒì  í™˜ê²½ë³€ìˆ˜ ëˆ„ë½ (ê¸°ëŠ¥ ì œí•œ): {', '.join(missing)}")
    
    print("âœ… [ENV] í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ í™•ì¸ ì™„ë£Œ")

_check_env()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Gmail SMTP
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _send_gmail(to, subject: str, html: str) -> bool:
    """
    Gmail SMTPë¡œ ì´ë©”ì¼ ë°œì†¡
    
    Returns:
        bool: ë°œì†¡ ì„±ê³µ ì—¬ë¶€
    """
    if not GMAIL_PASS:
        print("  âš ï¸ [Email] GMAIL_APP_PASSWORD ë¯¸ì„¤ì • â€” ë©”ì¼ ë°œì†¡ ìŠ¤í‚µ")
        return False
    
    recipients = [to] if isinstance(to, str) else to
    msg = MIMEMultipart("alternative")
    msg["Subject"] = subject
    msg["From"]    = f"Fitz Intelligence <{GMAIL_USER}>"
    msg["To"]      = ", ".join(recipients)
    msg.attach(MIMEText(html, "html", "utf-8"))
    
    try:
        with smtplib.SMTP_SSL("smtp.gmail.com", 465, timeout=30) as s:
            s.login(GMAIL_USER, GMAIL_PASS)
            s.sendmail(GMAIL_USER, recipients, msg.as_string())
        print(f"  âœ… [Email] ë°œì†¡ ì„±ê³µ: {recipients}")
        return True
    except smtplib.SMTPAuthenticationError as e:
        print(f"  ğŸš¨ [Email] ì¸ì¦ ì‹¤íŒ¨ (ê³„ì •/ë¹„ë°€ë²ˆí˜¸ í™•ì¸ í•„ìš”): {e}")
        return False
    except smtplib.SMTPException as e:
        print(f"  ğŸš¨ [Email] SMTP ì˜¤ë¥˜: {e}")
        return False
    except Exception as e:
        print(f"  ğŸš¨ [Email] ë°œì†¡ ì‹¤íŒ¨: {e}")
        return False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¡œê·¸ / ì„±ê³¼ / ë¹„ìš© ê¸°ë¡
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def log_to_db(user_id, target_word, action="ë¶„ì„", method="Auto"):
    try:
        supabase.table("action_logs").insert({
            "user_id": user_id, "action_type": action,
            "target_word": target_word, "execution_method": method, "details": "Success"
        }).execute()
    except: pass

def record_performance(user_id, keyword, count):
    try:
        supabase.table("keyword_performance").insert({
            "user_id": user_id, "keyword": keyword,
            "hit_count": count, "report_date": TODAY
        }).execute()
    except: pass

def record_cost(call_type: str, input_tokens: int, output_tokens: int,
                model: str = _DEFAULT_MODEL, count: int = 1):
    try:
        price = _GEMINI_PRICE.get(model, _GEMINI_PRICE[_DEFAULT_MODEL])
        cost  = (input_tokens / 1000 * price["input"]
                 + output_tokens / 1000 * price["output"]) * count
        supabase.table("cost_log").insert({
            "log_date":      TODAY,
            "call_type":     call_type,
            "model":         model,
            "call_count":    count,
            "input_tokens":  input_tokens,
            "output_tokens": output_tokens,
            "cost_usd":      round(cost, 6),
        }).execute()
    except Exception as e:
        print(f"  âš ï¸ [Cost] ê¸°ë¡ ì‹¤íŒ¨: {e}")

def record_supabase_stats():
    try:
        counts = {}
        total  = 0
        for tbl in _MONITOR_TABLES:
            try:
                res = supabase.table(tbl).select("id", count="exact").limit(1).execute()
                n   = res.count or 0
                counts[tbl] = n
                total += n
            except:
                counts[tbl] = -1
        supabase.table("supabase_stats").upsert({
            "stat_date":  TODAY,
            "row_counts": counts,
            "total_rows": total,
            "updated_at": NOW.isoformat(),
        }, on_conflict="stat_date").execute()
        print(f"ğŸ“Š [Stats] Supabase row ìŠ¤ëƒ…ìƒ· ì €ì¥ ì™„ë£Œ (total={total:,})")
    except Exception as e:
        print(f"  âš ï¸ [Stats] ìŠ¤ëƒ…ìƒ· ì €ì¥ ì‹¤íŒ¨: {e}")

def get_agents():
    res = supabase.table("agents").select("*").execute()
    return {a['agent_role']: a for a in (res.data or [])}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Gemini í˜¸ì¶œ â€” ììœ  í…ìŠ¤íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def call_agent(prompt, agent_info, persona_override=None, force_one_line=False):
    if not agent_info: return "ë¶„ì„ ë°ì´í„° ì—†ìŒ"
    role  = persona_override or agent_info.get('agent_role', 'Assistant')
    guard = " (ì£¼ì˜: ê³ ê° ë¦¬í¬íŠ¸ì´ë¯€ë¡œ ë‚´ë¶€ í•™ìŠµ ì œì•ˆì´ë‚˜ 'ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤' ê°™ì€ ë§ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ë§ˆí¬ë‹¤ìš´ ë³¼ë“œ(**), í—¤ë”(##), ë²ˆí˜¸ëª©ë¡(1.) ë“± ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.)"
    fp    = f"(ê²½ê³ : ë°˜ë“œì‹œ 'ë”± 1ì¤„'ë¡œë§Œ í•µì‹¬ì„ ì‘ì„±í•˜ë¼. ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì ˆëŒ€ ê¸ˆì§€) {prompt}" if force_one_line else prompt + guard

    for attempt in range(3):
        try:
            res = google_genai.models.generate_content(
                model=_DEFAULT_MODEL,
                contents=f"ë‹¹ì‹ ì€ {role}ì…ë‹ˆë‹¤.\nì§€ì¹¨: {agent_info['instruction']}\n\nì…ë ¥: {fp}"
            )
            try:
                usage = res.usage_metadata
                record_cost(
                    call_type     = agent_info.get('agent_role', 'UNKNOWN'),
                    input_tokens  = getattr(usage, 'prompt_token_count',     0),
                    output_tokens = getattr(usage, 'candidates_token_count', 0),
                )
            except: pass

            output = strip_markdown(res.text.strip())
            return output.split('\n')[0] if force_one_line else output

        except Exception as e:
            err = str(e)
            if '429' in err and attempt < 2:
                wait = 5 * (attempt + 1)
                print(f"  â³ [Gemini 429] {wait}ì´ˆ í›„ ì¬ì‹œë„ ({attempt+1}/3)...")
                time.sleep(wait)
            else:
                print(f"  âŒ [Gemini ì˜¤ë¥˜] {err[:80]}")
                return "ë¶„ì„ ì§€ì—° ì¤‘"
    return "ë¶„ì„ ì§€ì—° ì¤‘"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Gemini í˜¸ì¶œ â€” JSON ì „ìš©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def call_agent_json(prompt, agent_info, persona_override=None):
    if not agent_info: return {"summary": "ë¶„ì„ ë°ì´í„° ì—†ìŒ", "points": [], "deep": []}
    role  = persona_override or agent_info.get('agent_role', 'Assistant')
    guard = " (ì£¼ì˜: ê³ ê° ë¦¬í¬íŠ¸ì´ë¯€ë¡œ ë‚´ë¶€ í•™ìŠµ ì œì•ˆì´ë‚˜ 'ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤' ê°™ì€ ë§ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. JSON ê°’ ì•ˆì—ë„ ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(**,##,*,- ë“±)ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.)"

    json_instruction = """

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ë¼. ë§ˆí¬ë‹¤ìš´, ì½”ë“œë¸”ë¡, ì„¤ëª… í…ìŠ¤íŠ¸ ì¼ì ˆ ê¸ˆì§€.
JSON ê°’ ì•ˆì— **, *, ##, ë²ˆí˜¸ëª©ë¡(1. 2.) ë“± ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆë¼.
{
  "summary": "í•µì‹¬ í•œ ì¤„ ìš”ì•½ (40~60ì, ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì—†ì´ í‰ë¬¸ìœ¼ë¡œ)",
  "points": ["í¬ì¸íŠ¸1 (1~2ë¬¸ì¥, í‰ë¬¸)", "í¬ì¸íŠ¸2 (1~2ë¬¸ì¥, í‰ë¬¸)", "í¬ì¸íŠ¸3 (1~2ë¬¸ì¥, í‰ë¬¸)"],
  "deep": ["ì‹¬ì¸µë¶„ì„1 (1~2ë¬¸ì¥, í‰ë¬¸)", "ì‹¬ì¸µë¶„ì„2", "ì‹¬ì¸µë¶„ì„3", "ì‹¬ì¸µë¶„ì„4"]
}
"""
    full_prompt = prompt + guard + json_instruction

    for attempt in range(3):
        try:
            res = google_genai.models.generate_content(
                model=_DEFAULT_MODEL,
                contents=f"ë‹¹ì‹ ì€ {role}ì…ë‹ˆë‹¤.\nì§€ì¹¨: {agent_info['instruction']}\n\nì…ë ¥: {full_prompt}"
            )
            try:
                usage = res.usage_metadata
                record_cost(
                    call_type     = agent_info.get('agent_role', 'UNKNOWN'),
                    input_tokens  = getattr(usage, 'prompt_token_count',     0),
                    output_tokens = getattr(usage, 'candidates_token_count', 0),
                )
            except: pass

            raw = res.text.strip()
            raw = re.sub(r"^```json\s*", "", raw)
            raw = re.sub(r"\s*```$",     "", raw)
            raw = raw.strip()
            brace_start = raw.find('{')
            brace_end   = raw.rfind('}')
            if brace_start != -1 and brace_end != -1:
                raw = raw[brace_start:brace_end + 1]
            parsed = json.loads(raw)

            # JSON ê°’ ì•ˆì— ë‚¨ì€ ë§ˆí¬ë‹¤ìš´ë„ í›„ì²˜ë¦¬ë¡œ ì œê±°
            parsed['summary'] = strip_markdown(str(parsed.get('summary', '')))
            parsed['points']  = [strip_markdown(str(p)) for p in parsed.get('points', [])]
            parsed['deep']    = [strip_markdown(str(d)) for d in parsed.get('deep', [])]
            return parsed

        except json.JSONDecodeError:
            print(f"  âš ï¸ [JSON] [{role}] íŒŒì‹± ì‹¤íŒ¨ ({attempt+1}/3) â€” ì¬ì‹œë„")
            if attempt == 2:
                try:
                    supabase.table("action_logs").insert({
                        "action_type":      "JSON_PARSE_FAIL",
                        "target_word":      role,
                        "execution_method": "Auto",
                        "details":          f"3íšŒ íŒŒì‹± ì‹¤íŒ¨. ì›ë¬¸ ì• 100ì: {res.text[:100]}"
                    }).execute()
                except: pass
                return {"summary": strip_markdown(res.text.strip().split('\n')[0][:80]), "points": [], "deep": []}
            time.sleep(2)
            continue

        except Exception as e:
            err = str(e)
            if '429' in err and attempt < 2:
                wait = 5 * (attempt + 1)
                print(f"  â³ [Gemini 429] {wait}ì´ˆ í›„ ì¬ì‹œë„ ({attempt+1}/3)...")
                time.sleep(wait)
            else:
                print(f"  âŒ [Gemini ì˜¤ë¥˜] {err[:80]}")
                return {"summary": "ë¶„ì„ ì§€ì—° ì¤‘", "points": [], "deep": []}

    return {"summary": "ë¶„ì„ ì§€ì—° ì¤‘", "points": [], "deep": []}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# YouTube API í—¬í¼ / ìˆ˜ì§‘ / ìºì‹œ / ì»¨í…ìŠ¤íŠ¸ ë¹Œë”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _yt_get(url: str, params: dict) -> dict:
    query = "&".join(f"{k}={urllib.parse.quote(str(v))}" for k, v in params.items())
    try:
        with urllib.request.urlopen(f"{url}?{query}", timeout=10) as r:
            return json.loads(r.read().decode())
    except Exception as e:
        print(f"  âš ï¸ [YT API] ì˜¤ë¥˜: {e}")
        return {}

def collect_youtube(keyword: str, max_recent: int = 2, max_popular: int = 2) -> list:
    if not YOUTUBE_KEY:
        print("  âš ï¸ [YT] YOUTUBE_API_KEY ì—†ìŒ â€” YouTube ìˆ˜ì§‘ ê±´ë„ˆëœ€")
        return []

    results, seen_ids = [], set()

    for order_type, max_n in [("date", max_recent), ("viewCount", max_popular)]:
        raw = _yt_get(YT_SEARCH_URL, {
            "key":               YOUTUBE_KEY,
            "q":                 keyword,
            "part":              "snippet",
            "type":              "video",
            "order":             order_type,
            "maxResults":        max_n,
            "relevanceLanguage": "ko",
            "regionCode":        "KR",
            "publishedAfter":    (NOW - timedelta(days=7)).strftime("%Y-%m-%dT00:00:00Z"),
        })

        items = raw.get("items", [])
        if not items:
            continue

        video_ids   = [it["id"]["videoId"] for it in items if it["id"].get("videoId")]
        channel_ids = list({it["snippet"]["channelId"] for it in items})

        stats_raw = _yt_get(YT_VIDEO_URL, {
            "key":  YOUTUBE_KEY,
            "id":   ",".join(video_ids),
            "part": "statistics",
        })
        stats_map = {
            s["id"]: int(s["statistics"].get("viewCount", 0))
            for s in stats_raw.get("items", [])
        }

        ch_raw = _yt_get(YT_CHANNEL_URL, {
            "key":  YOUTUBE_KEY,
            "id":   ",".join(channel_ids),
            "part": "statistics",
        })
        ch_map = {
            c["id"]: int(c["statistics"].get("subscriberCount", 0))
            for c in ch_raw.get("items", [])
        }

        for it in items:
            vid = it["id"].get("videoId")
            if not vid or vid in seen_ids:
                continue
            seen_ids.add(vid)
            sn    = it["snippet"]
            ch_id = sn["channelId"]
            subs  = ch_map.get(ch_id, 0)
            results.append({
                "title":            sn["title"],
                "channel":          sn["channelTitle"],
                "channel_id":       ch_id,
                "video_id":         vid,
                "url":              f"https://www.youtube.com/watch?v={vid}",
                "published":        sn.get("publishedAt", "")[:10],
                "view_count":       stats_map.get(vid, 0),
                "subscriber_count": subs,
                "is_expert":        subs >= EXPERT_SUBSCRIBER_THRESHOLD,
                "order_type":       "ìµœì‹ " if order_type == "date" else "ì¸ê¸°",
                "keyword":          keyword,
            })

    expert_cnt = sum(1 for v in results if v["is_expert"])
    print(f"  ğŸ¬ [YT] '{keyword}' â†’ {len(results)}ê°œ ìˆ˜ì§‘ (ì „ë¬¸ê°€/ì¸í”Œë£¨ì–¸ì„œ ì±„ë„ {expert_cnt}ê°œ)")
    return results

def get_youtube_with_cache(keyword: str) -> list:
    try:
        cache = supabase.table("youtube_cache")\
            .select("videos")\
            .eq("keyword", keyword)\
            .eq("cache_date", TODAY)\
            .execute()
        if cache.data:
            print(f"  ğŸ¬ [YT Cache] '{keyword}' â†’ ìºì‹œ ë°ì´í„° ì¬ì‚¬ìš©")
            return cache.data[0]["videos"]
    except Exception as e:
        print(f"  âš ï¸ [YT Cache] ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {e}")

    videos = collect_youtube(keyword)

    try:
        supabase.table("youtube_cache").upsert({
            "keyword":    keyword,
            "cache_date": TODAY,
            "videos":     videos,
        }, on_conflict="keyword,cache_date").execute()
        print(f"  ğŸ’¾ [YT Cache] '{keyword}' â†’ ìºì‹œ ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        print(f"  âš ï¸ [YT Cache] ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")

    return videos

_EXPERT_DOMAINS = [
    "kdi.re.kr", "nipa.kr", "iitp.kr", "kisdi.re.kr",
    "kotra.or.kr", "kiet.re.kr", "kiep.go.kr", "kistep.re.kr",
    "mckinsey.com", "bcg.com", "deloitte.com", "pwc.com",
    "gartner.com", "hbr.org", "mit.edu", "stanford.edu",
    "hankyung.com", "mk.co.kr", "sedaily.com",
    "zdnet.co.kr", "etnews.com", "techcrunch.com",
    "venturebeat.com", "bloomberg.com", "reuters.com", "ft.com",
    # ìƒˆë¡œ ì¶”ê°€
    "yozm.wishket.com", "brunch.co.kr", "theverge.com",

_NORMAL_DOMAINS = [
    "naver.com", "daum.net", "joins.com", "chosun.com",
    "donga.com", "hani.co.kr", "yonhapnews.co.kr",
]

def collect_expert_contents(word: str, agents: dict, max_per_domain: int = 2) -> list:
    """
    master.htmlì˜ agents.crawl_sitesë¥¼ ìš°ì„  ì‚¬ìš©í•˜ê³ , 
    ë¶€ì¡±í•˜ë©´ í•˜ë“œì½”ë”© ë„ë©”ì¸ìœ¼ë¡œ ë³´ì¶©
    """
    print(f"  ğŸ“ [{word}] ì „ë¬¸ ì½˜í…ì¸  ìˆ˜ì§‘ ì‹œì‘...")
    brief_agent = agents.get('BRIEF')
    collected   = []
    seen_titles = set()
    
    # â•â•â• 1ë‹¨ê³„: DBì—ì„œ crawl_sites ë¡œë“œ â•â•â•
    db_domains = []
    try:
        agent_res = supabase.table("agents").select("agent_role, crawl_sites").execute()
        for a in (agent_res.data or []):
            sites = a.get("crawl_sites") or []
            for site in sites:
                if isinstance(site, dict) and site.get("policy") == "allow":
                    url = site.get("url", "")
                    if url:
                        domain = url.replace("https://", "").replace("http://", "").split("/")[0]
                        db_domains.append(domain)
        
        db_domains = list(dict.fromkeys(db_domains))
        if db_domains:
            print(f"    ğŸ’¾ [DB] master.htmlì—ì„œ ë“±ë¡ëœ ì‚¬ì´íŠ¸ {len(db_domains)}ê°œ ë¡œë“œ")
    except Exception as e:
        print(f"    âš ï¸ [DB] crawl_sites ì¡°íšŒ ì‹¤íŒ¨ ({e}) â€” í•˜ë“œì½”ë”© ì‚¬ìš©")
    
    # â•â•â• 2ë‹¨ê³„: DB + Fallback ë³‘í•© â•â•â•
    expert_domains = []
    if db_domains:
        expert_domains.extend(db_domains[:15])
    
    if len(expert_domains) < 5:
        needed = 10 - len(expert_domains)
        print(f"    ğŸ”„ [Fallback] DB ë„ë©”ì¸ ë¶€ì¡± â€” í•˜ë“œì½”ë”© {needed}ê°œ ë³´ì¶©")
        expert_domains.extend(_EXPERT_DOMAINS[:needed])
    
    # â•â•â• 3ë‹¨ê³„: í¬ë¡¤ë§ í•¨ìˆ˜ â•â•â•
    def _scrape(domain: str, is_expert: bool):
        try:
            lang = _DOMAIN_LANG.get(domain, 'en')
            gn = GNews(language=lang, max_results=max_per_domain)
            news = gn.get_news(f"{word} site:{domain}") or []
            
            for n in news:
                title = (n.get("title") or "").strip()
                url = n.get("url") or n.get("link") or ""
                if not title or title in seen_titles or not url:
                    continue
                seen_titles.add(title)
                
                expert_summary = ""
                if brief_agent:
                    try:
                        raw = call_agent(
                            f"ì•„ë˜ ì œëª©ì˜ í•µì‹¬ì„ 40ì ì´ë‚´ 1ì¤„ë¡œ ìš”ì•½. ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€.\nì œëª©: {title}",
                            brief_agent, force_one_line=True
                        )
                        expert_summary = strip_markdown(raw).split('\n')[0][:80]
                    except: pass
                
                collected.append({
                    "title": title,
                    "url": url,
                    "source_domain": domain,
                    "is_expert_content": is_expert,
                    "expert_summary": expert_summary,
                })
            
            if news:
                print(f"    ğŸ“Œ [Expert] [{domain}] '{word}' â†’ {len(news)}ê±´")
        except Exception as e:
            print(f"    âš ï¸ [Expert] [{domain}] ì‹¤íŒ¨: {e}")
    
    # â•â•â• 4ë‹¨ê³„: Expert ë„ë©”ì¸ í¬ë¡¤ë§ â•â•â•
    for domain in expert_domains:
        if len(collected) >= 10: break
        _scrape(domain, is_expert=True)
    
    # â•â•â• 5ë‹¨ê³„: ë¶€ì¡± ì‹œ ì¼ë°˜ ë„ë©”ì¸ ë³´ì¶© â•â•â•
    if len(collected) < 3:
        print(f"  ğŸ“Œ [Expert] ë¶€ì¡±({len(collected)}ê±´) â€” ì¼ë°˜ ë„ë©”ì¸ ë³´ì¶©")
        for domain in _NORMAL_DOMAINS:
            if len(collected) >= 6: break
            _scrape(domain, is_expert=False)
    
    # â•â•â• 6ë‹¨ê³„: ì •ë ¬ ë° ê²°ê³¼ ì¶œë ¥ â•â•â•
    collected.sort(key=lambda x: (0 if x["is_expert_content"] else 1))
    expert_count = sum(1 for c in collected if c["is_expert_content"])
    normal_count = len(collected) - expert_count
    
    print(f"  âœ… [Expert] '{word}' â†’ ì´ {len(collected)}ê±´ "
          f"(ì‹¬ì¸µ:{expert_count}ê±´ / ì¼ë°˜:{normal_count}ê±´)")
    return collected


# ë‹¤ìŒ í•¨ìˆ˜ë¡œ ë°”ë¡œ ì´ì–´ì§ (ì„¤ëª… í…ìŠ¤íŠ¸ ì—†ì´)
def get_expert_with_cache(word: str, agents: dict) -> list:
    try:
        cache = supabase.table("expert_cache") \
            .select("contents").eq("keyword", word).eq("cache_date", TODAY).execute()
        if cache.data:
            print(f"  ğŸ“ [Expert Cache] '{word}' â†’ ìºì‹œ ì¬ì‚¬ìš©")
            return cache.data[0]["contents"]
    except Exception as e:
        print(f"  âš ï¸ [Expert Cache] ì¡°íšŒ ì‹¤íŒ¨: {e}")

    contents = collect_expert_contents(word, agents)

    try:
        supabase.table("expert_cache").upsert({
            "keyword":    word,
            "cache_date": TODAY,
            "contents":   contents,
        }, on_conflict="keyword,cache_date").execute()
        print(f"  ğŸ’¾ [Expert Cache] '{word}' â†’ ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        print(f"  âš ï¸ [Expert Cache] ì €ì¥ ì‹¤íŒ¨: {e}")

    return contents

def get_expert_with_cache(word: str, agents: dict) -> list:
    try:
        cache = supabase.table("expert_cache") \
            .select("contents").eq("keyword", word).eq("cache_date", TODAY).execute()
        if cache.data:
            print(f"  ğŸ“ [Expert Cache] '{word}' â†’ ìºì‹œ ì¬ì‚¬ìš©")
            return cache.data[0]["contents"]
    except Exception as e:
        print(f"  âš ï¸ [Expert Cache] ì¡°íšŒ ì‹¤íŒ¨: {e}")

    contents = collect_expert_contents(word, agents)

    try:
        supabase.table("expert_cache").upsert({
            "keyword":    word,
            "cache_date": TODAY,
            "contents":   contents,
        }, on_conflict="keyword,cache_date").execute()
        print(f"  ğŸ’¾ [Expert Cache] '{word}' â†’ ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        print(f"  âš ï¸ [Expert Cache] ì €ì¥ ì‹¤íŒ¨: {e}")

    return contents
    
def build_youtube_context(yt_videos: list) -> str:
    if not yt_videos:
        return ""
    lines = ["[YouTube ì½˜í…ì¸  ì¸ì‚¬ì´íŠ¸]"]
    for v in yt_videos:
        tag = "â­ì „ë¬¸ê°€/ì¸í”Œë£¨ì–¸ì„œ" if v["is_expert"] else "ì¼ë°˜ì±„ë„"
        lines.append(
            f"- [{v['keyword']}][{v['order_type']}] {v['title']} "
            f"| ì±„ë„: {v['channel']}({tag}, êµ¬ë…{v['subscriber_count']:,}) "
            f"| ì¡°íšŒ{v['view_count']:,} | {v['published']}"
        )
    return "\n".join(lines)

def build_youtube_email_block(yt_videos: list) -> str:
    if not yt_videos:
        return ""
    cards = ""
    for v in yt_videos[:6]:
        tag     = "â­ ì „ë¬¸ê°€/ì¸í”Œë£¨ì–¸ì„œ" if v["is_expert"] else "ì¼ë°˜ì±„ë„"
        tag_clr = "#f59e0b" if v["is_expert"] else "#94a3b8"
        cards += f"""
          <tr>
            <td style="padding:10px 0; border-bottom:1px solid #f0f0f0;">
              <p style="margin:0 0 2px 0; font-size:11px; font-weight:700; color:{tag_clr};">{tag} Â· {v['keyword']}</p>
              <a href="{v['url']}" style="font-size:14px; font-weight:600; color:#1a1a1a; text-decoration:none; line-height:1.4;">{v['title']}</a>
              <p style="margin:4px 0 0 0; font-size:12px; color:#94a3b8;">{v['channel']} Â· êµ¬ë… {v['subscriber_count']:,} Â· ì¡°íšŒ {v['view_count']:,}</p>
            </td>
          </tr>"""
    return f"""
        <table width="100%" cellpadding="0" cellspacing="0" style="margin-bottom:32px;">
          <tr><td style="padding-bottom:12px;">
            <h2 style="margin:0 0 0 0; font-size:18px; font-weight:700; color:#111;">ğŸ¬ ìœ íŠœë¸Œ ì¸ì‚¬ì´íŠ¸</h2>
          </td></tr>
          {cards}
        </table>"""

def send_email_report(to_email: str, report: dict, yt_videos: list) -> bool:
    """
    ì´ë©”ì¼ ë¦¬í¬íŠ¸ ë°œì†¡ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
    
    Args:
        to_email: ìˆ˜ì‹ ì ì´ë©”ì¼
        report: ë¦¬í¬íŠ¸ ë°ì´í„°
        yt_videos: YouTube ì˜ìƒ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        bool: ë°œì†¡ ì„±ê³µ ì—¬ë¶€
    """
    html = _build_email_html(report, yt_videos)
    subject = f"ğŸ“Š {TODAY} Fitz Intelligence ì¼ì¼ ë¸Œë¦¬í•‘"
    
    # ìµœëŒ€ 3íšŒ ì¬ì‹œë„
    for attempt in range(3):
        try:
            success = _send_gmail(to_email, subject, html)
            
            if success:
                print(f"  âœ… [{to_email}] ì´ë©”ì¼ ë°œì†¡ ì„±ê³µ (ì‹œë„ {attempt + 1}/3)")
                return True
            else:
                if attempt < 2:
                    wait_time = 2 ** attempt  # 1ì´ˆ, 2ì´ˆ
                    print(f"  â³ [{to_email}] {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(wait_time)
                else:
                    print(f"  âŒ [{to_email}] ì´ë©”ì¼ ë°œì†¡ ìµœì¢… ì‹¤íŒ¨")
                    return False
                    
        except Exception as e:
            print(f"  ğŸš¨ [{to_email}] ë°œì†¡ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            if attempt < 2:
                time.sleep(2 ** attempt)
            else:
                return False
    
    return False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GitHub ë™ê¸°í™”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _run_cmd(cmd: str):
    res = subprocess.run(cmd, shell=True, text=True, capture_output=True)
    if res.returncode != 0:
        out = (res.stderr or res.stdout or "").strip()
        raise RuntimeError(f"ëª…ë ¹ ì‹¤íŒ¨: {cmd} :: {out[:240]}")
    return res

def sync_data_to_github():
    try:
        print("ğŸ“ [Sync] GitHub ì €ì¥ì†Œ ë™ê¸°í™” ì‹œì‘...")
        res = supabase.table("reports").select("*").eq("report_date", TODAY).execute()
        with open("data.json", "w", encoding="utf-8") as f:
            json.dump(res.data, f, ensure_ascii=False, indent=2)

        _run_cmd('git config --global user.name "Fitz-Dev"')
        _run_cmd('git config --global user.email "positivecha@gmail.com"')
        _run_cmd('git add data.json')

        staged = subprocess.run(
            "git diff --cached --quiet -- data.json",
            shell=True
        ).returncode
        if staged == 0:
            print("â„¹ï¸ [Sync] data.json ë³€ê²½ ì—†ìŒ â€” push ìŠ¤í‚µ")
            return

        _run_cmd(f'git commit -m "ğŸ“Š [Data Sync] {TODAY} Insights Update"')
        branch = os.environ.get("GITHUB_REF_NAME") or "main"
        _run_cmd(f"git push origin HEAD:{branch}")
        print("ğŸš€ [Sync] GitHub data.json ê°±ì‹  ì™„ë£Œ")
    except Exception as e:
        print(f"ğŸš¨ [Sync] ë™ê¸°í™” ì‹¤íŒ¨: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# [1] DEV ì—”ì§„: ì§€ì • backlog ì‘ì—… ì§‘í–‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _validate_generated_code(file_path: str, new_code: str):
    compile(new_code, file_path, "exec")
    if os.path.basename(file_path) != "news_bot.py":
        return
    required = [
        "def run_autonomous_engine(",
        "def run_agent_initiative(",
        'if __name__ == "__main__":',
    ]
    missing = [sig for sig in required if sig not in new_code]
    if missing:
        raise ValueError(f"í•µì‹¬ êµ¬ì¡° ëˆ„ë½: {', '.join(missing)}")
    if len(new_code.splitlines()) < 300:
        raise ValueError("í•µì‹¬ ëŸ°íƒ€ì„ ì½”ë“œê°€ ë¹„ì •ìƒì ìœ¼ë¡œ ì¶•ì†Œë˜ì–´ ë°°í¬ ì°¨ë‹¨")


def run_self_evolution(backlog_id: str):
    task     = None
    cur_code = None
    file_path = None

    def _notify(subject, body, is_fail=False):
        icon = "ğŸš¨" if is_fail else "âœ…"
        try:
            _send_gmail(
                to      = "positivecha@gmail.com",
                subject = f"{icon} [DEV] {subject}",
                html    = f"<pre style='font-family:monospace'>{body}</pre>",
            )
        except Exception as mail_err:
            print(f"  âš ï¸ [DEV] ì•Œë¦¼ ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {mail_err}")
            try:
                supabase.table("action_logs").insert({
                    "action_type":      "DEV_NOTIFY_FAIL",
                    "target_word":      subject,
                    "execution_method": "Auto",
                    "details":          str(mail_err)[:200]
                }).execute()
            except: pass

    if not backlog_id:
        print("â„¹ï¸ [DEV] backlog_id ë¯¸ì§€ì • â€” ì½”ë“œ ë°°í¬ ë‹¨ê³„ ìŠ¤í‚µ")
        return

    try:
        task_res = supabase.table("dev_backlog").select("*")\
            .eq("id", backlog_id).limit(1).execute()
        if not task_res.data:
            return print(f"ğŸ’¤ [DEV] backlog_id={backlog_id} ì‘ì—… ì—†ìŒ â€” ìŠ¤í‚µ")

        task      = task_res.data[0]
        status    = (task.get("status") or "").upper()
        if status not in {"CONFIRMED", "DEVELOPING"}:
            return print(f"ğŸ’¤ [DEV] backlog_id={backlog_id} ìƒíƒœ={status} â€” ë°°í¬ ìŠ¤í‚µ")

        file_path = task.get('affected_file', 'news_bot.py')
        print(f"ğŸ› ï¸ [DEV] ë§ˆìŠ¤í„° ì§€íœ˜ ì—…ë¬´ ì°©ìˆ˜: {task['title']}")

        with open(file_path, "r", encoding="utf-8") as f:
            cur_code = f.read()

        try:
            supabase.table("code_backups").insert({
                "file_path":    file_path,
                "code":         cur_code,
                "task_id":      task['id'],
                "task_title":   task['title'],
                "backed_up_at": NOW.isoformat()
            }).execute()
            print(f"  ğŸ’¾ [DEV] ë°±ì—… ì €ì¥ ì™„ë£Œ (Supabase code_backups)")
        except Exception as bk_err:
            msg = f"ë°±ì—… ì €ì¥ ì‹¤íŒ¨ë¡œ ì‘ì—… ì¤‘ë‹¨.\nì˜¤ë¥˜: {bk_err}"
            print(f"  ğŸš¨ [DEV] {msg}")
            _notify(f"ë°±ì—… ì‹¤íŒ¨ â€” '{task['title']}' ì¤‘ë‹¨", msg, is_fail=True)
            supabase.table("dev_backlog").update({"status": "BACKUP_FAILED"})\
                .eq("id", task['id']).execute()
            return

        bk = "backups"
        if not os.path.exists(bk): os.makedirs(bk)
        shutil.copy2(file_path, f"{bk}/{file_path}.{NOW.strftime('%H%M%S')}.bak")

        agents     = get_agents()
        dev_prompt = (
            f"ìš”êµ¬ì‚¬í•­: {task['task_detail']}\n\n"
            "ë°˜ë“œì‹œ ì „ì²´ ì½”ë“œë¥¼ ```python ... ``` ì•ˆì— ì¶œë ¥.\n"
            f"--- í˜„ì¬ ì½”ë“œ ---\n{cur_code}"
        )
        raw      = call_agent(dev_prompt, agents.get('DEV'), "Senior Python Engineer")
        m        = re.search(r"```python\s+(.*?)\s+```", raw, re.DOTALL)
        new_code = m.group(1).strip() if m else raw.strip()

        try:
            _validate_generated_code(file_path, new_code)
            print(f"  âœ… [DEV] êµ¬ì¡°/ë¬¸ë²• ê²€ì‚¬ í†µê³¼")
        except Exception as syn_err:
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(cur_code)
            print(f"  ğŸš¨ [DEV] ê²€ì¦ ì‹¤íŒ¨ ê°ì§€ â†’ ë¡¤ë°± ì™„ë£Œ, push ì°¨ë‹¨")
            err_detail = (
                f"ì‘ì—…: {task['title']}\n"
                f"ì˜¤ë¥˜ ìœ í˜•: {type(syn_err).__name__}\n"
                f"ë‚´ìš©: {str(syn_err)}\n\n"
                f"ì¡°ì¹˜: ì›ë³¸ ì½”ë“œë¡œ ìë™ ë¡¤ë°± ì™„ë£Œ. GitHub pushëŠ” ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
                f"ë°±ì—… IDëŠ” Supabase code_backups í…Œì´ë¸”ì—ì„œ í™•ì¸í•˜ì„¸ìš”."
            )
            _notify(f"ê²€ì¦ ì‹¤íŒ¨ â€” '{task['title']}' ë¡¤ë°±", err_detail, is_fail=True)
            supabase.table("dev_backlog").update({"status": "VALIDATION_ERROR"})\
                .eq("id", task['id']).execute()
            return

        with open(file_path, "w", encoding="utf-8") as f:
            f.write(new_code)

        _run_cmd('git config --global user.name "Fitz-Dev"')
        _run_cmd('git config --global user.email "positivecha@gmail.com"')
        _run_cmd(f'git add {file_path}')
        task_title = task["title"][:60]
        _run_cmd(f'git commit -m "ğŸ¤– [DEV] {task_title}"')
        branch = os.environ.get("GITHUB_REF_NAME") or "main"
        _run_cmd(f"git push origin HEAD:{branch}")

        supabase.table("dev_backlog").update({"status": "DEPLOYED"})\
            .eq("id", task['id']).execute()
        print(f"  ğŸš€ [DEV] ë°°í¬ ì™„ë£Œ: {task['title']}")
        _notify(f"ë°°í¬ ì™„ë£Œ â€” '{task['title']}'", f"ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ë°°í¬ë˜ì—ˆìŠµë‹ˆë‹¤.\n{task['task_detail'][:200]}")

    except Exception as e:
        msg = f"ì‘ì—…: {task['title'] if task else 'ì•Œ ìˆ˜ ì—†ìŒ'}\nì˜¤ë¥˜: {e}"
        print(f"ğŸš¨ [DEV] ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        _notify("DEV ì²˜ë¦¬ ì‹¤íŒ¨", msg, is_fail=True)
        if task:
            supabase.table("dev_backlog").update({"status": "DEPLOY_FAILED"})\
                .eq("id", task['id']).execute()
        if cur_code and file_path:
            try:
                with open(file_path, "w", encoding="utf-8") as f:
                    f.write(cur_code)
                print(f"  â†©ï¸ [DEV] ì›ë³¸ ì½”ë“œë¡œ ë¡¤ë°± ì™„ë£Œ")
            except: pass

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# [2] ì—ì´ì „íŠ¸ ìì•„ ì„±ì°°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_agent_self_reflection(report_id):
    try:
        fb = supabase.table("report_feedback").select("*").eq("report_id", report_id).execute()
        if not fb.data: return
        agents = get_agents()
        for role, info in agents.items():
            if role in ['DEV', 'QA', 'MASTER']: continue
            neg = [f['feedback_text'] for f in fb.data if f['target_agent'] == role and not f['is_positive']]
            if not neg: continue
            rp = (
                f"í˜„ì¬ ì§€ì¹¨: {info['instruction']}\nê³ ê°ë¶ˆë§Œ: {', '.join(neg)}\n\n"
                "ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ìƒì‹ í•˜ë¼.\n"
                "[PROPOSAL]ìˆ˜ì •ì§€ì¹¨ "
                "[REASON]ìˆ˜ì •ê·¼ê±° "
                "[NEEDS_DEV]ì½”ë“œ ìˆ˜ì • ì—†ì´ ì§€ì¹¨ ë³€ê²½ë§Œìœ¼ë¡œ í•´ê²° ê°€ëŠ¥í•˜ë©´ NO, ì½”ë“œ ë³€ê²½ì´ í•„ìš”í•˜ë©´ YES"
            )
            ref = call_agent(rp, info, "Insight Evolver")
            p   = re.search(r"\[PROPOSAL\](.*?)(?=\[REASON\]|$)",   ref, re.DOTALL)
            r   = re.search(r"\[REASON\](.*?)(?=\[NEEDS_DEV\]|$)",  ref, re.DOTALL)
            nd  = re.search(r"\[NEEDS_DEV\](.*?)$",                  ref, re.DOTALL)
            if p:
                needs_dev = "YES" in (nd.group(1).strip().upper() if nd else "NO")
                supabase.table("pending_approvals").insert({
                    "agent_role":           role,
                    "proposed_instruction": p.group(1).strip(),
                    "proposal_reason":      r.group(1).strip() if r else "VOC í”¼ë“œë°± ë°˜ì˜",
                    "needs_dev":            needs_dev
                }).execute()
    except: pass

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# [3] ë°ë“œë¼ì¸ ìë™ ìŠ¹ì¸ + dev_backlog ìë™ ë“±ë¡
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def manage_deadline_approvals():
    if NOW.hour == 23 and NOW.minute >= 30:
        try:
            pending = supabase.table("pending_approvals").select("*").eq("status", "PENDING").execute()
            for item in (pending.data or []):
                supabase.table("agents").update({
                    "instruction": item['proposed_instruction']
                }).eq("agent_role", item['agent_role']).execute()

                supabase.table("pending_approvals").update({
                    "status": "APPROVED"
                }).eq("id", item['id']).execute()

                if item.get('needs_dev'):
                    dup = supabase.table("dev_backlog")\
                        .select("id")\
                        .eq("source_approval_id", item['id'])\
                        .execute()
                    if dup.data:
                        print(f"  â­ï¸ [DEV Backlog] ì´ë¯¸ ë“±ë¡ëœ ì•ˆê±´ ìŠ¤í‚µ: {item['id']}")
                        continue
                    supabase.table("dev_backlog").insert({
                        "title":              f"[ìë™ë“±ë¡] {item['agent_role']} â€” {item.get('proposal_reason', '')[:50]}",
                        "task_detail":        item['proposed_instruction'],
                        "affected_file":      "news_bot.py",
                        "priority":           10,
                        "status":             "PENDING_MASTER",
                        "source_approval_id": item['id']
                    }).execute()
                    print(f"  ğŸ“‹ [DEV Backlog] ìë™ ë“±ë¡ ì™„ë£Œ: {item['agent_role']} ì•ˆê±´ â†’ ëŒ€í‘œë‹˜ ìŠ¹ì¸ ëŒ€ê¸°")

        except Exception as e:
            print(f"ğŸš¨ [Approvals] ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# [4] ì´ë©”ì¼ ë°œì†¡ â€” ë‰´ìŠ¤ë ˆí„° í…œí”Œë¦¿ (ì „ë¬¸ ì½˜í…ì¸  í¬í•¨)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _build_email_html(report, yt_videos=None):
    bk        = report.get("by_keyword", {})
    yt_videos = yt_videos or []

    keyword_sections = ""
    kw_list = list(bk.items())

    for idx, (kw, kd) in enumerate(kw_list):
        articles = kd.get("articles", [])
        expert_contents = kd.get("expert_contents", [])[:3]  # â† ì¶”ê°€
        ba_brief = kd.get("ba_brief", {})

        # ê¸°ì‚¬ ì„¹ì…˜
        article_rows = ""
        for a in articles[:3]:
            title      = a.get("title", "")
            pm_summary = strip_markdown(a.get("pm_summary", ""))
            url        = a.get("url", a.get("link", "#"))
            article_rows += f"""
              <tr>
                <td style="padding:10px 0; border-bottom:1px solid #f0f0f0;">
                  <p style="margin:0 0 4px 0; font-size:14px; font-weight:600; color:#1a1a1a; line-height:1.4;">{title}</p>
                  <p style="margin:0 0 6px 0; font-size:13px; color:#666; line-height:1.5;">{pm_summary}</p>
                  <a href="{url}" style="font-size:12px; color:#2563eb; font-weight:700; text-decoration:none;">ë” ìì„¸íˆ ì•Œì•„ë³´ê¸° â†’</a>
                </td>
              </tr>"""

        # ì „ë¬¸ ì½˜í…ì¸  ì„¹ì…˜ (ìƒˆë¡œ ì¶”ê°€)
        expert_rows = ""
        if expert_contents:
            expert_rows = """
            <tr><td style="padding-top:16px;">
              <div style="font-size:11px;font-weight:700;color:#7c3aed;letter-spacing:1px;margin-bottom:10px;">ğŸ“ EXPERT INSIGHTS</div>
            </td></tr>"""
            
            for exp in expert_contents:
                exp_title = exp.get("title", "")
                exp_url = exp.get("url", "#")
                exp_summary = exp.get("expert_summary", "")
                exp_source = exp.get("source_domain", "")
                
                expert_rows += f"""
                <tr><td style="padding:10px 0; border-bottom:1px solid #f3e8ff;">
                  <a href="{exp_url}" style="color:#7c3aed;font-weight:600;font-size:14px;text-decoration:none;line-height:1.4;">{exp_title}</a>
                  <div style="font-size:11px;color:#94a3b8;margin-top:3px;">{exp_source}</div>
                  <div style="font-size:13px;color:#64748b;margin-top:6px;line-height:1.5;">{exp_summary}</div>
                </td></tr>"""

        # BA ë¸Œë¦¬í•‘ ì„¹ì…˜
        if isinstance(ba_brief, dict):
            ba_items = []
            if ba_brief.get("summary"):
                ba_items.append(strip_markdown(ba_brief["summary"]))
            ba_items += [strip_markdown(p) for p in ba_brief.get("points", [])]
        else:
            ba_items = [strip_markdown(l.strip()) for l in str(ba_brief).split('\n') if l.strip()][:5]

        ba_html = "".join(
            f'<li style="margin-bottom:6px; color:#444; font-size:13px; line-height:1.6;">{l}</li>'
            for l in ba_items if l
        )

        divider = ""
        if idx < len(kw_list) - 1:
            divider = """
              <table width="100%" cellpadding="0" cellspacing="0" style="margin-bottom:32px;">
                <tr><td style="border-top:1px solid #f0f0f0;"></td></tr>
              </table>"""

        keyword_sections += f"""
        <table width="100%" cellpadding="0" cellspacing="0" style="margin-bottom:24px;">
          <tr>
            <td style="padding-bottom:14px;">
              <span style="display:inline-block; background:#f0f4ff; color:#2563eb; font-size:11px; font-weight:700; padding:4px 10px; border-radius:20px; letter-spacing:.5px;"># {kw}</span>
            </td>
          </tr>
          <tr><td>{article_rows and f'<table width="100%" cellpadding="0" cellspacing="0">{article_rows}</table>' or ''}</td></tr>
          {expert_rows and f'<tr><td><table width="100%" cellpadding="0" cellspacing="0">{expert_rows}</table></td></tr>' or ''}
          {ba_html and f'<tr><td style="padding-top:14px;"><ul style="margin:0; padding-left:18px;">{ba_html}</ul></td></tr>' or ''}
        </table>
        {divider}"""

    yt_block        = build_youtube_email_block(yt_videos)
    dashboard_block = f"""
        <table width="100%" cellpadding="0" cellspacing="0" style="background:#0f172a; border-radius:10px; margin-top:32px;">
          <tr>
            <td style="padding:28px 32px; text-align:center;">
              <p style="margin:0 0 16px 0; font-size:18px; font-weight:700; color:#fff;">ì˜¤ëŠ˜ì˜ ì „ì²´ ì¸ì‚¬ì´íŠ¸ í™•ì¸í•˜ê¸°</p>
              <a href="{DASHBOARD_URL}" style="display:inline-block; background:#e8472a; color:#fff; font-size:14px; font-weight:700; padding:14px 32px; border-radius:10px; text-decoration:none;">ëŒ€ì‹œë³´ë“œ ë°”ë¡œê°€ê¸° â†’</a>
            </td>
          </tr>
        </table>"""

    return f"""<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Fitz ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë¦¬í¬íŠ¸</title>
</head>
<body style="margin:0; padding:0; background-color:#f9fafb; font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,'Helvetica Neue',Arial,sans-serif;">
  <table width="100%" cellpadding="0" cellspacing="0" style="background-color:#f9fafb; padding:40px 20px;">
    <tr>
      <td align="center">
        <table width="100%" cellpadding="0" cellspacing="0" style="max-width:600px; background:#fff; border-radius:16px; box-shadow:0 4px 20px rgba(0,0,0,0.08);">
          <tr>
            <td style="padding:32px 32px 24px 32px;">
              <h1 style="margin:0 0 8px 0; font-size:26px; font-weight:800; color:#111; letter-spacing:-0.5px;">ğŸ“Š ì˜¤ëŠ˜ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸</h1>
              <p style="margin:0; font-size:14px; color:#94a3b8;">{TODAY}</p>
            </td>
          </tr>
          <tr><td style="padding:0 32px 32px 32px;">{keyword_sections}</td></tr>
          {yt_block and f'<tr><td style="padding:0 32px 32px 32px;">{yt_block}</td></tr>' or ''}
          <tr><td style="padding:0 32px 32px 32px;">{dashboard_block}</td></tr>
          <tr>
            <td style="padding:24px 32px; background:#f8fafc; border-top:1px solid #e2e8f0; text-align:center;">
              <p style="margin:0; font-size:12px; color:#94a3b8;">
                Â© 2025 Fitz Intelligence. All rights reserved.
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
</body>
</html>"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# [BRIEF ì—­í•  â‘ ] ì§ì› ìˆ˜ì§‘ ì†ŒìŠ¤ ì§€ì‹œ + ì‹¤ì œ í¬ë¡¤ë§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_DOMAIN_LANG = {
    "reuters.com": "en", "bloomberg.com": "en", "ft.com": "en",
    "techcrunch.com": "en", "wsj.com": "en", "cnbc.com": "en",
    "naver.com": "ko", "naver_finance": "ko", "hankyung.com": "ko",
    "mk.co.kr": "ko", "chosun.com": "ko", "joins.com": "ko",
    "zdnet.co.kr": "ko", "platum.kr": "ko", "venturebeat.com": "en",
    "investing.com": "en", "seekingalpha.com": "en",
    "jobplanet.co.kr": "ko", "linkedin.com": "en",
    # ìƒˆë¡œ ì¶”ê°€
    "yozm.wishket.com": "ko",
    "brunch.co.kr": "ko",
    "theverge.com": "en",
}

def brief_get_source_directive(word: str, agents: dict) -> dict:
    brief_agent = agents.get('BRIEF')
    if not brief_agent:
        return {}

    prompt = (
        f"í‚¤ì›Œë“œ: '{word}'\n\n"
        "ë‹¹ì‹ ì€ ë¶„ì„íŒ€ ë¦¬ë”(BRIEF)ì…ë‹ˆë‹¤. "
        "ì˜¤ëŠ˜ ì´ í‚¤ì›Œë“œì™€ ê´€ë ¨í•´ ê° ë‹´ë‹¹ì(BA, STOCK, PM, HR)ê°€ "
        "ì–´ë–¤ ì‚¬ì´íŠ¸ë‚˜ ì†ŒìŠ¤ì—ì„œ ì½˜í…ì¸ ë¥¼ ì§‘ì¤‘ ìˆ˜ì§‘í•´ì•¼ í•˜ëŠ”ì§€ ì§€ì‹œí•˜ì‹­ì‹œì˜¤.\n\n"
        "ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ë¼. ì„¤ëª…Â·ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€.\n"
        "ì‚¬ì´íŠ¸ëª…ì€ ë„ë©”ì¸ í˜•ì‹(ì˜ˆ: reuters.com, hankyung.com)ìœ¼ë¡œ ì‘ì„±.\n"
        "{\n"
        '  "BA":    ["ì‚¬ì´íŠ¸1", "ì‚¬ì´íŠ¸2"],\n'
        '  "STOCK": ["ì‚¬ì´íŠ¸1", "ì‚¬ì´íŠ¸2"],\n'
        '  "PM":    ["ì‚¬ì´íŠ¸1", "ì‚¬ì´íŠ¸2"],\n'
        '  "HR":    ["ì‚¬ì´íŠ¸1", "ì‚¬ì´íŠ¸2"]\n'
        "}"
    )

    raw = call_agent(prompt, brief_agent, force_one_line=False)
    try:
        raw_clean = re.sub(r"```[a-z]*|```", "", raw).strip()
        brace_s = raw_clean.find('{')
        brace_e = raw_clean.rfind('}')
        if brace_s != -1 and brace_e != -1:
            raw_clean = raw_clean[brace_s:brace_e+1]
        directive = json.loads(raw_clean)
        print(f"  ğŸ“‹ [BRIEFâ†’ì§ì›] '{word}' ìˆ˜ì§‘ ì†ŒìŠ¤ ì§€ì‹œ ì™„ë£Œ: {directive}")
        return directive
    except Exception as e:
        print(f"  âš ï¸ [BRIEFâ†’ì§ì›] íŒŒì‹± ì‹¤íŒ¨ ({e}) â€” ê¸°ë³¸ ì†ŒìŠ¤ ì‚¬ìš©")
        return {}


def collect_news_by_directive(word: str, directive: dict) -> list:
    all_sources = []
    for role_sources in directive.values():
        all_sources.extend(role_sources)
    unique_sources = list(dict.fromkeys(all_sources))

    if not unique_sources:
        is_korean = any(ord(c) > 0x1100 for c in word)
        gn = GNews(language='ko' if is_korean else 'en', max_results=10)
        return gn.get_news(word) or []

    collected = []
    seen_titles = set()

    for domain in unique_sources:
        try:
            lang = _DOMAIN_LANG.get(domain, None)
            if lang is None:
                lang = 'ko' if any(ord(c) > 0x1100 for c in domain) else 'en'

            site_query = f"{word} site:{domain}" if '.' in domain else word
            gn = GNews(language=lang, max_results=3)
            news = gn.get_news(site_query) or []

            for n in news:
                title = n.get("title", "")
                if title and title not in seen_titles:
                    seen_titles.add(title)
                    n['source_domain'] = domain
                    collected.append(n)

            if news:
                print(f"    ğŸ“Œ [{domain}] '{word}' â†’ {len(news)}ê±´ ìˆ˜ì§‘")

        except Exception as e:
            print(f"    âš ï¸ [{domain}] ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            continue

    if len(collected) < 5:
        try:
            is_korean = any(ord(c) > 0x1100 for c in word)
            gn = GNews(language='ko' if is_korean else 'en', max_results=10)
            fallback = gn.get_news(word) or []
            for n in fallback:
                title = n.get("title", "")
                if title and title not in seen_titles:
                    seen_titles.add(title)
                    n['source_domain'] = 'gnews_fallback'
                    collected.append(n)
            print(f"    ğŸ”„ [GNews ë³´ì¶©] '{word}' â†’ {len(fallback)}ê±´ ì¶”ê°€")
        except Exception as e:
            print(f"    âš ï¸ [GNews ë³´ì¶©] ì‹¤íŒ¨: {e}")

    print(f"  ğŸ“° [BRIEF ì§€ì‹œ ìˆ˜ì§‘] '{word}' ì´ {len(collected)}ê±´ (ì†ŒìŠ¤: {unique_sources})")
    return collected


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# [BRIEF ì—­í•  â‘¡] ì „ë¬¸ ì½˜í…ì¸  í¬ë¡¤ë§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def collect_expert_contents(word: str, directive: dict) -> list:
    """
    Briefê°€ ì§€ì‹œí•œ ì†ŒìŠ¤ì—ì„œ ì „ë¬¸ ì½˜í…ì¸ ë¥¼ í¬ë¡¤ë§í•œë‹¤.
    ë‰´ìŠ¤ì™€ ë‹¬ë¦¬ ì‹¬ì¸µ ë¶„ì„, ë¦¬í¬íŠ¸, ë¸”ë¡œê·¸ ë“±ì„ ìˆ˜ì§‘í•œë‹¤.
    """
    # ëª¨ë“  ì—­í• ì˜ ì†ŒìŠ¤ë¥¼ í•©ì³ì„œ ìƒìœ„ 3ê°œ ì‚¬ì´íŠ¸ ì„ ì •
    all_sources = []
    for role_sources in directive.values():
        all_sources.extend(role_sources)
    
    unique_sources = list(dict.fromkeys(all_sources))[:3]  # ìƒìœ„ 3ê°œë§Œ
    
    if not unique_sources:
        print(f"  â„¹ï¸ [Expert] '{word}' ì§€ì •ëœ ì†ŒìŠ¤ ì—†ìŒ")
        return []
    
    collected = []
    seen_titles = set()
    
    for domain in unique_sources:
        try:
            # ì „ë¬¸ ì½˜í…ì¸ ëŠ” ì¼ë°˜ ë‰´ìŠ¤ë³´ë‹¤ ê¹Šì´ ìˆëŠ” í‚¤ì›Œë“œ ì¡°í•© ì‚¬ìš©
            search_queries = [
                f"{word} analysis site:{domain}",
                f"{word} report site:{domain}",
                f"{word} insight site:{domain}",
            ]
            
            lang = _DOMAIN_LANG.get(domain, 'en' if '.' in domain else 'ko')
            
            for query in search_queries:
                try:
                    gn = GNews(language=lang, max_results=2)
                    results = gn.get_news(query) or []
                    
                    for item in results:
                        title = item.get("title", "")
                        url = item.get("url", "")
                        
                        # ì¤‘ë³µ ì œê±° ë° í’ˆì§ˆ í•„í„°
                        if title and title not in seen_titles and len(title) > 20:
                            seen_titles.add(title)
                            
                            # ì „ë¬¸ ì½˜í…ì¸  ì ìˆ˜ ê³„ì‚° (ì œëª© ê¸°ë°˜ íœ´ë¦¬ìŠ¤í‹±)
                            is_expert = any(keyword in title.lower() for keyword in [
                                'analysis', 'report', 'insight', 'research', 'study',
                                'ë¶„ì„', 'ë¦¬í¬íŠ¸', 'ë³´ê³ ì„œ', 'ì—°êµ¬', 'ì‹¬ì¸µ'
                            ])
                            
                            collected.append({
                                **item,
                                'source_domain': domain,
                                'is_expert_content': is_expert,
                                'keyword': word,
                            })
                    
                    if results:
                        print(f"    ğŸ“ [{domain}] '{query}' â†’ {len(results)}ê±´ ìˆ˜ì§‘")
                        time.sleep(1)  # Rate limiting
                        
                except Exception as e:
                    print(f"    âš ï¸ [{domain}] '{query}' ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    continue
                    
        except Exception as e:
            print(f"    âš ï¸ [{domain}] ì „ì²´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            continue
    
    print(f"  ğŸ“ [Expert Contents] '{word}' ì´ {len(collected)}ê±´ (ì†ŒìŠ¤: {unique_sources})")
    return collected

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# [5] ììœ¨ ë¶„ì„ ì—”ì§„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_autonomous_engine():
    agents = get_agents()
    print(f"ğŸš€ {TODAY} Sovereign Engine v18.0 ê°€ë™")

    user_res = supabase.table("user_settings").select("*").execute()
    for user in (user_res.data or []):
        try:
            user_id    = user['id']
            user_email = user.get('email', 'Unknown')
            keywords   = user.get('keywords', [])[:5]
            if not keywords: continue

            chk = supabase.table("reports").select("id, email_sent").eq("user_id", user_id).eq("report_date", TODAY).execute()
            if chk.data and chk.data[0].get("email_sent"):
                print(f"â­ï¸  [Skip] {user_email} â€” ì´ë¯¸ ë°œì†¡ ì™„ë£Œ")
                continue

            print(f"ğŸ” [{user_email}] í‚¤ì›Œë“œ {keywords} ë¶„ì„ ì‹œì‘")

            by_keyword   = {}
            all_articles = []
            all_yt       = []

            for word in keywords:
                print(f"  ğŸ“‹ [{word}] BRIEF ìˆ˜ì§‘ ì†ŒìŠ¤ ì§€ì‹œ ì¤‘...")
                source_directive = brief_get_source_directive(word, agents)
                ba_src  = source_directive.get('BA',    [])
                pm_src  = source_directive.get('PM',    [])
                stk_src = source_directive.get('STOCK', [])

                print(f"  ğŸ“° [{word}] BRIEF ì§€ì‹œ ì†ŒìŠ¤ ê¸°ë°˜ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
                news_list = collect_news_by_directive(word, source_directive)

                record_performance(user_id, word, len(news_list))

                if not news_list:
                    print(f"  âš ï¸  [{word}] ë‰´ìŠ¤ ì—†ìŒ â€” ìŠ¤í‚µ")
                    by_keyword[word] = {
                        "ba_brief":         {"summary": "í•´ë‹¹ í‚¤ì›Œë“œì˜ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "points": [], "deep": []},
                        "securities_brief": {"summary": "í•´ë‹¹ í‚¤ì›Œë“œì˜ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "points": [], "deep": []},
                        "pm_brief":         {"summary": "í•´ë‹¹ í‚¤ì›Œë“œì˜ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "points": [], "deep": []},
                        "articles":         [],
                        "youtube_videos":   [],
                        "expert_contents":  [],
                        "source_directive": source_directive,
                    }
                    continue

                articles = []
                kw_ctx   = []
                for n in news_list:
                    # pm_summary: 1ì¤„ ìš”ì•½ í›„ ë§ˆí¬ë‹¤ìš´ ì œê±°
                    pm_summary_raw = call_agent(
                        f"ë‰´ìŠ¤: {n['title']}", agents['BRIEF'], force_one_line=True
                    )
                    pm_summary = strip_markdown(pm_summary_raw).split('\n')[0]

                    impact_raw = call_agent(
                        f"ë‰´ìŠ¤: {n['title']}\nì „ë§ 1ì¤„.",
                        agents.get('STOCK', agents['BRIEF']),
                        force_one_line=True
                    )
                    impact = strip_markdown(impact_raw).split('\n')[0]

                    articles.append({**n, "keyword": word, "pm_summary": pm_summary, "impact": impact})
                    kw_ctx.append(n['title'])
                    all_articles.append(f"[{word}] {n['title']}")

                print(f"  ğŸ¬ [{word}] YouTube ìˆ˜ì§‘ ì¤‘...")
                yt_videos = get_youtube_with_cache(word)
                all_yt.extend(yt_videos)
                yt_ctx = build_youtube_context(yt_videos)
                print(f"  ğŸ“ [{word}] ì „ë¬¸ ì½˜í…ì¸  ìˆ˜ì§‘ ì¤‘...")
                expert_contents = get_expert_with_cache(word, agents)
                
                # ===== ì „ë¬¸ ì½˜í…ì¸  ìˆ˜ì§‘ (ì¶”ê°€) =====
                print(f"  ğŸ“ [{word}] ì „ë¬¸ ì½˜í…ì¸  ìˆ˜ì§‘ ì¤‘...")
                expert_contents = collect_expert_contents(word, source_directive)
                
                # ì „ë¬¸ ì½˜í…ì¸  ìš”ì•½ ìƒì„±
                expert_summaries = []
                for content in expert_contents[:3]:  # ìƒìœ„ 3ê°œë§Œ
                    try:
                        summary_raw = call_agent(
                            f"ì „ë¬¸ ì½˜í…ì¸ : {content['title']}\ní•µì‹¬ ì¸ì‚¬ì´íŠ¸ 1ì¤„ë¡œ ìš”ì•½",
                            agents['BRIEF'],
                            force_one_line=True
                        )
                        summary = strip_markdown(summary_raw).split('\n')[0]
                        content['expert_summary'] = summary
                        expert_summaries.append(content)
                        time.sleep(1)  # Rate limiting
                    except Exception as e:
                        print(f"    âš ï¸ ì „ë¬¸ ì½˜í…ì¸  ìš”ì•½ ì‹¤íŒ¨: {e}")
                        content['expert_summary'] = content.get('description', '')[:100]
                        expert_summaries.append(content)

                # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
                ctx = "\n".join(kw_ctx)
                if yt_ctx:
                    ctx += f"\n\n{yt_ctx}"

                hint_ba  = f"\n\n[BRIEF ì§€ì‹œ â€” ì˜¤ëŠ˜ ì¤‘ì  ì°¸ê³  ì†ŒìŠ¤: {', '.join(ba_src)}]"  if ba_src  else ""
                hint_pm  = f"\n\n[BRIEF ì§€ì‹œ â€” ì˜¤ëŠ˜ ì¤‘ì  ì°¸ê³  ì†ŒìŠ¤: {', '.join(pm_src)}]"  if pm_src  else ""
                hint_stk = f"\n\n[BRIEF ì§€ì‹œ â€” ì˜¤ëŠ˜ ì¤‘ì  ì°¸ê³  ì†ŒìŠ¤: {', '.join(stk_src)}]" if stk_src else ""

                print(f"  ğŸ¤– [{word}] ì—ì´ì „íŠ¸ ë¶„ì„ ì¤‘...")
                by_keyword[word] = {
                    "ba_brief": call_agent_json(
                        f"í‚¤ì›Œë“œ '{word}' ë‰´ìŠ¤ ë° ìœ íŠœë¸Œ ê¸°ë°˜ ë¹„ì¦ˆë‹ˆìŠ¤ ìˆ˜ìµ êµ¬ì¡° ë° ê²½ìŸ ë¶„ì„:\n{ctx}{hint_ba}",
                        agents['BA']
                    ),
                    "securities_brief": call_agent_json(
                        f"í‚¤ì›Œë“œ '{word}' ë‰´ìŠ¤ ë° ìœ íŠœë¸Œ ê¸°ë°˜ ì£¼ì‹ ì‹œì¥ ë°˜ì‘ ë° íˆ¬ì ì¸ì‚¬ì´íŠ¸:\n{ctx}{hint_stk}",
                        agents['STOCK']
                    ),
                    "pm_brief": call_agent_json(
                        f"í‚¤ì›Œë“œ '{word}' ë‰´ìŠ¤ ë° ìœ íŠœë¸Œ ê¸°ë°˜ ì „ëµì  ì„œë¹„ìŠ¤ ê¸°íš ë¸Œë¦¬í•‘:\n{ctx}{hint_pm}",
                        agents['PM']
                    ),
                    "articles":         articles,
                    "youtube_videos":   yt_videos,
                    "expert_contents":  expert_summaries,  # â† ì¶”ê°€
                    "source_directive": source_directive,
                }

            if not by_keyword:
                print(f"âš ï¸  [{user_email}] ë¶„ì„ ê²°ê³¼ ì—†ìŒ â€” ìŠ¤í‚µ")
                continue

            all_ctx     = "\n".join(all_articles)
            hr_proposal = call_agent(
                f"ì¡°ì§ ë° ì¸ì‚¬ ê´€ë¦¬ ì œì•ˆ (ì „ì²´ í‚¤ì›Œë“œ ê¸°ë°˜):\n{all_ctx}",
                agents['HR']
            )

            final_report = {
                "by_keyword":  by_keyword,
                "hr_proposal": hr_proposal,
            }

            res = supabase.table("reports").upsert({
                "user_id":     user_id,
                "report_date": TODAY,
                "content":     final_report,
                "qa_score":    95
            }, on_conflict="user_id,report_date").execute()

            if res.data:
                report_id = res.data[0]['id']
                run_agent_self_reflection(report_id)
                
                # ì´ë©”ì¼ ë°œì†¡ ë° ì„±ê³µ ì—¬ë¶€ í™•ì¸
                email_success = send_email_report(user_email, final_report, all_yt)
                
                # email_sent í”Œë˜ê·¸ ì—…ë°ì´íŠ¸ (ì¬ì‹œë„ 3íšŒ)
                for retry in range(3):
                    try:
                        supabase.table("reports").update({"email_sent": email_success})\
                            .eq("id", report_id).execute()
                        print(f"  âœ… [DB] email_sent={email_success} ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                        break
                    except Exception as e:
                        if retry < 2:
                            print(f"  â³ [DB] email_sent ì—…ë°ì´íŠ¸ ì¬ì‹œë„ ({retry + 1}/3)...")
                            time.sleep(1)
                        else:
                            print(f"  ğŸš¨ [DB] email_sent ì—…ë°ì´íŠ¸ ìµœì¢… ì‹¤íŒ¨: {e}")
                            # ìµœì¢… ì‹¤íŒ¨ ì‹œ ê´€ë¦¬ìì—ê²Œ ì•Œë¦¼
                            try:
                                _send_gmail(
                                    to="positivecha@gmail.com",
                                    subject="ğŸš¨ [ì‹œìŠ¤í…œ] email_sent ì—…ë°ì´íŠ¸ ì‹¤íŒ¨",
                                    html=f"<pre>report_id: {report_id}\nuser: {user_email}\nerror: {e}</pre>"
                                )
                            except:
                                pass
                
                status_msg = "ì´ë©”ì¼ ë°œì†¡ ì™„ë£Œ" if email_success else "ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨ (DBì— ê¸°ë¡ë¨)"
                print(f"âœ… [{user_email}] ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ (YouTube {len(all_yt)}ê°œ í¬í•¨) â€” {status_msg}")

        except Exception as e:
            print(f"âŒ ìœ ì € ì—ëŸ¬ ({user.get('email','?')}): {e}")
            continue

    record_supabase_stats()
    sync_data_to_github()
    run_agent_initiative(by_keyword_all=_collect_all_by_keyword(user_res.data or []))


def _collect_all_by_keyword(users: list) -> dict:
    """ëª¨ë“  ìœ ì €ì˜ by_keyword ë°ì´í„°ë¥¼ ë³‘í•©"""
    merged = {}
    try:
        res = supabase.table("reports").select("content").eq("report_date", TODAY).execute()
        for r in (res.data or []):
            for kw, kd in (r.get("content", {}).get("by_keyword", {}) or {}).items():
                if kw not in merged:
                    merged[kw] = kd
    except: pass
    return merged

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# [6] ì‚°ì—…êµ° ìë™ ëª¨ë‹ˆí„°ë§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_industry_monitor():
    print("ğŸ­ [Industry] ì‚°ì—…êµ° ëª¨ë‹ˆí„°ë§ ì‹œì‘...")
    try:
        ind_map = supabase.table("industry_map")\
            .select("industry, keywords")\
            .eq("is_active", True).execute()
    except Exception as e:
        print(f"  âš ï¸ [Industry] industry_map ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return

    agents = get_agents()

    for row in (ind_map.data or []):
        industry = row.get("industry", "")
        kws      = row.get("keywords", [])
        if not industry or not kws:
            continue

        all_articles = []
        for kw in kws[:3]:
            try:
                is_korean = any(ord(c) > 0x1100 for c in kw)
                gn        = GNews(language='ko' if is_korean else 'en', max_results=3)
                news      = gn.get_news(kw)
                all_articles.extend([{"title": n["title"], "keyword": kw} for n in news])
            except Exception as e:
                print(f"  âš ï¸ [Industry] '{kw}' ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

        if not all_articles:
            continue

        ctx = "\n".join([f"[{a['keyword']}] {a['title']}" for a in all_articles])
        try:
            summary = call_agent(
                f"ì‚°ì—…êµ° '{industry}' ì˜¤ëŠ˜ ë‰´ìŠ¤ ë™í–¥ 3ì¤„ ìš”ì•½:\n{ctx}",
                agents.get("BA", agents.get("BRIEF")),
                force_one_line=False
            )
        except:
            summary = "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"

        try:
            supabase.table("industry_monitor").upsert({
                "industry":     industry,
                "category":     industry,   # NOT NULL ì œì•½ â€” industry ê°’ìœ¼ë¡œ ì±„ì›€
                "articles":     all_articles,
                "summary":      summary,
                "monitor_date": TODAY,
            }, on_conflict="industry,monitor_date").execute()
            print(f"  âœ… [Industry] '{industry}' ë™í–¥ ì €ì¥ ì™„ë£Œ ({len(all_articles)}ê±´)")
        except Exception as e:
            print(f"  âŒ [Industry] '{industry}' ì €ì¥ ì‹¤íŒ¨: {e}")

    print("ğŸ­ [Industry] ì‚°ì—…êµ° ëª¨ë‹ˆí„°ë§ ì™„ë£Œ")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# [BRIEF ì—­í•  â‘¢] BRIEFâ†’HR ì—ì´ì „íŠ¸ ì¡°ì§ íŒŒì´í”„ë¼ì¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_brief_hr_org_pipeline(agents: dict, today_ctx: str, industry_ctx: str):
    brief_agent = agents.get('BRIEF')
    hr_agent    = agents.get('HR')
    if not brief_agent or not hr_agent:
        print("  âš ï¸ [BRIEFâ†’HR] BRIEF ë˜ëŠ” HR ì—ì´ì „íŠ¸ ì—†ìŒ â€” íŒŒì´í”„ë¼ì¸ ìŠ¤í‚µ")
        return

    try:
        agent_res     = supabase.table("agents").select("agent_role").execute()
        current_roles = [a['agent_role'] for a in (agent_res.data or [])]
        current_roles_str = ", ".join(current_roles) if current_roles else "ì—†ìŒ"
    except Exception as e:
        print(f"  âš ï¸ [BRIEFâ†’HR] ì—ì´ì „íŠ¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return

    print("  ğŸ§  [BRIEF] ì—ì´ì „íŠ¸ ì¡°ì§ êµ¬ì„± ì œì•ˆ ìƒì„± ì¤‘...")

    brief_prompt = (
        f"ì˜¤ëŠ˜ ë‰´ìŠ¤ ì»¨í…ìŠ¤íŠ¸:\n{today_ctx}\n\n"
        f"ì‚°ì—…êµ° ë™í–¥:\n{industry_ctx}\n\n"
        f"í˜„ì¬ ê°€ë™ ì¤‘ì¸ ì—ì´ì „íŠ¸: {current_roles_str}\n\n"
        "ë‹¹ì‹ ì€ ë¶„ì„íŒ€ ë¦¬ë”(BRIEF)ì…ë‹ˆë‹¤. "
        "ì˜¤ëŠ˜ ë‰´ìŠ¤ì™€ ì‚°ì—… ë™í–¥ì„ ë¶„ì„í•´, í˜„ì¬ íŒ€ì—ì„œ ë¶€ì¡±í•˜ê±°ë‚˜ ìƒˆë¡œ í•„ìš”í•œ ì „ë¬¸ê°€ ì—­í• ì„ ì œì•ˆí•˜ê³ , "
        "ì„±ê³¼ê°€ ë‚®ê±°ë‚˜ ì¤‘ë³µë˜ëŠ” ì—­í• ì€ ì œê±°ë¥¼ ì œì•ˆí•˜ì‹­ì‹œì˜¤.\n\n"
        "ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ë¼. ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(**,*,## ë“±) ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€:\n"
        "[ADD_AGENT]ì—­í• ëª…1:ì—­í• ì„¤ëª…1|ì—­í• ëª…2:ì—­í• ì„¤ëª…2\n"
        "[REMOVE_AGENT]ì—­í• ëª…1:ì œê±°ì´ìœ 1|ì—­í• ëª…2:ì œê±°ì´ìœ 2\n"
        "[REASON]ì „ì²´ íŒë‹¨ ê·¼ê±°ë¥¼ 2~3ì¤„ë¡œ ì„¤ëª…\n\n"
        "ì¶”ê°€/ì œê±°ê°€ í•„ìš” ì—†ìœ¼ë©´ í•´ë‹¹ íƒœê·¸ ë’¤ì— 'ì—†ìŒ'ì´ë¼ê³  ì ì„ ê²ƒ.\n"
        f"ì ˆëŒ€ë¡œ {', '.join(_PROTECTED_ROLES)} ì—­í• ì€ ì œê±° ì œì•ˆí•˜ì§€ ë§ ê²ƒ."
    )

    brief_proposal = call_agent(brief_prompt, brief_agent, force_one_line=False)

    if not brief_proposal or brief_proposal in ["ë¶„ì„ ì§€ì—° ì¤‘", "ë¶„ì„ ë°ì´í„° ì—†ìŒ"]:
        print("  âš ï¸ [BRIEF] ì—ì´ì „íŠ¸ ì¡°ì§ ì œì•ˆ ì—†ìŒ â€” ìŠ¤í‚µ")
        return

    print(f"  âœ… [BRIEF] ì¡°ì§ ì œì•ˆ ì™„ë£Œ")

    print("  ğŸ‘¤ [HR] BRIEF ì œì•ˆ ì‹¬ì‚¬ ì¤‘...")
    hr_prompt = (
        f"BRIEF ë¦¬ë”ì˜ ì—ì´ì „íŠ¸ ì¡°ì§ ê°œí¸ ì œì•ˆ:\n{brief_proposal}\n\n"
        f"í˜„ì¬ ê°€ë™ ì¤‘ì¸ ì—ì´ì „íŠ¸: {current_roles_str}\n"
        f"ì˜¤ëŠ˜ ë‰´ìŠ¤ ì»¨í…ìŠ¤íŠ¸:\n{today_ctx}\n\n"
        "ë‹¹ì‹ ì€ HR ì±…ì„ìì…ë‹ˆë‹¤. "
        "BRIEFì˜ ì œì•ˆì„ í•­ëª©ë³„ë¡œ ì‹¬ì‚¬í•˜ì—¬ íƒ€ë‹¹í•œ ê²ƒì€ ìŠ¹ì¸, ë¶€ì ì ˆí•œ ê²ƒì€ ê±°ë¶€í•˜ì‹­ì‹œì˜¤.\n\n"
        "ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ë¼. ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(**,*,## ë“±) ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€:\n"
        "[APPROVED_ADD]ì—­í• ëª…1:ì—­í• ì„¤ëª…1|ì—­í• ëª…2:ì—­í• ì„¤ëª…2  (ì—†ìœ¼ë©´ 'ì—†ìŒ')\n"
        "[APPROVED_REMOVE]ì—­í• ëª…1:ì œê±°ì´ìœ 1  (ì—†ìœ¼ë©´ 'ì—†ìŒ')\n"
        "[REJECTED]ê±°ë¶€ í•­ëª©ê³¼ ê±°ë¶€ ì´ìœ \n"
        "[HR_COMMENT]ìµœì¢… ì‹¬ì‚¬ ì˜ê²¬ 1~2ì¤„"
    )

    hr_decision = call_agent(hr_prompt, hr_agent, force_one_line=False)

    if not hr_decision or hr_decision in ["ë¶„ì„ ì§€ì—° ì¤‘", "ë¶„ì„ ë°ì´í„° ì—†ìŒ"]:
        print("  âš ï¸ [HR] ì‹¬ì‚¬ ê²°ê³¼ ì—†ìŒ â€” ìŠ¤í‚µ")
        return

    print(f"  âœ… [HR] ì‹¬ì‚¬ ì™„ë£Œ")

    add_m     = re.search(r"\[APPROVED_ADD\](.*?)(?=\[APPROVED_REMOVE\]|\[REJECTED\]|\[HR_COMMENT\]|$)",  hr_decision, re.DOTALL)
    remove_m  = re.search(r"\[APPROVED_REMOVE\](.*?)(?=\[APPROVED_ADD\]|\[REJECTED\]|\[HR_COMMENT\]|$)", hr_decision, re.DOTALL)
    comment_m = re.search(r"\[HR_COMMENT\](.*?)$", hr_decision, re.DOTALL)

    add_raw    = (add_m.group(1).strip()     if add_m     else "").strip()
    remove_raw = (remove_m.group(1).strip()  if remove_m  else "").strip()
    hr_comment = (comment_m.group(1).strip() if comment_m else "HR ì‹¬ì‚¬ ì™„ë£Œ").strip()

    approved_adds    = []
    approved_removes = []

    if add_raw and add_raw != "ì—†ìŒ":
        for item in add_raw.split("|"):
            parts = item.strip().split(":", 1)
            if len(parts) == 2:
                approved_adds.append((clean_role_name(parts[0]), parts[1].strip()))

    if remove_raw and remove_raw != "ì—†ìŒ":
        for item in remove_raw.split("|"):
            parts = item.strip().split(":", 1)
            if len(parts) == 2:
                approved_removes.append((clean_role_name(parts[0]), parts[1].strip()))

    for role_name, role_desc in approved_adds:
        if role_name in current_roles:
            print(f"  â­ï¸  [BRIEFâ†’HR] '{role_name}' ì´ë¯¸ ì¡´ì¬ â€” ìŠ¤í‚µ")
            continue
        try:
            content = (
                f"[ì‹ ê·œ ì—ì´ì „íŠ¸ ì¶”ê°€ ì œì•ˆ]\n"
                f"ì—­í• ëª…: {role_name}\n"
                f"ì—­í•  ì„¤ëª…: {role_desc}\n\n"
                f"[BRIEF ì›ë³¸ ì œì•ˆ]\n{brief_proposal}\n\n"
                f"[HR ì‹¬ì‚¬ ì˜ê²¬]\n{hr_comment}"
            )
            supabase.table("pending_approvals").insert({
                "agent_role":           role_name,
                "proposed_instruction": content,
                "proposal_reason":      f"{TODAY} BRIEF ì œì•ˆ â†’ HR ìŠ¹ì¸ â€” ì‹ ê·œ ì—ì´ì „íŠ¸ ì¶”ê°€",
                "needs_dev":            False,
                "status":               "PENDING",
            }).execute()
            print(f"  âœ… [BRIEFâ†’HR] ì‹ ê·œ ì—ì´ì „íŠ¸ '{role_name}' pending_approvals ë“±ë¡ ì™„ë£Œ")
        except Exception as e:
            print(f"  âŒ [BRIEFâ†’HR] '{role_name}' ë“±ë¡ ì‹¤íŒ¨: {e}")

    for role_name, remove_reason in approved_removes:
        if role_name in _PROTECTED_ROLES:
            print(f"  ğŸ›¡ï¸  [BRIEFâ†’HR] '{role_name}'ì€ ë³´í˜¸ ì—­í•  â€” ì œê±° ë¶ˆê°€")
            continue
        if role_name not in current_roles:
            print(f"  â­ï¸  [BRIEFâ†’HR] '{role_name}' ì¡´ì¬í•˜ì§€ ì•ŠìŒ â€” ìŠ¤í‚µ")
            continue
        try:
            content = (
                f"[ì—ì´ì „íŠ¸ ì œê±° ì œì•ˆ]\n"
                f"ì—­í• ëª…: {role_name}\n"
                f"ì œê±° ì´ìœ : {remove_reason}\n\n"
                f"[BRIEF ì›ë³¸ ì œì•ˆ]\n{brief_proposal}\n\n"
                f"[HR ì‹¬ì‚¬ ì˜ê²¬]\n{hr_comment}"
            )
            supabase.table("pending_approvals").insert({
                "agent_role":           role_name,
                "proposed_instruction": content,
                "proposal_reason":      f"{TODAY} BRIEF ì œì•ˆ â†’ HR ìŠ¹ì¸ â€” ì—ì´ì „íŠ¸ ì œê±°",
                "needs_dev":            False,
                "status":               "PENDING",
            }).execute()
            print(f"  âœ… [BRIEFâ†’HR] ì—ì´ì „íŠ¸ ì œê±° ì œì•ˆ '{role_name}' pending_approvals ë“±ë¡ ì™„ë£Œ")
        except Exception as e:
            print(f"  âŒ [BRIEFâ†’HR] '{role_name}' ì œê±° ì œì•ˆ ë“±ë¡ ì‹¤íŒ¨: {e}")

    if not approved_adds and not approved_removes:
        print(f"  â„¹ï¸  [BRIEFâ†’HR] ìŠ¹ì¸ëœ ë³€ê²½ ì—†ìŒ. HR ì˜ê²¬: {hr_comment}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# [7] ì—ì´ì „íŠ¸ ììœ¨ ë°œì˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_agent_initiative(by_keyword_all: dict):
    run_industry_monitor()
    print("ğŸ§  [Initiative] ì—ì´ì „íŠ¸ ììœ¨ ë°œì˜ ì‹œì‘...")
    agents = get_agents()

    ctx_lines = []
    for kw, kd in by_keyword_all.items():
        articles = kd.get("articles", [])
        titles   = [a.get("title", "") for a in articles[:3]]
        ctx_lines.append(f"[{kw}] " + " / ".join(titles))
    today_ctx = "\n".join(ctx_lines) if ctx_lines else "ì˜¤ëŠ˜ ìˆ˜ì§‘ëœ ë°ì´í„° ì—†ìŒ"

    try:
        perf = supabase.table("keyword_performance")\
            .select("keyword, hit_count")\
            .eq("report_date", TODAY).execute()
        perf_lines = [f"{p['keyword']}: {p['hit_count']}ê±´" for p in (perf.data or [])]
        perf_ctx = "\n".join(perf_lines) if perf_lines else "ì„±ê³¼ ë°ì´í„° ì—†ìŒ"
    except:
        perf_ctx = "ì„±ê³¼ ë°ì´í„° ì—†ìŒ"

    try:
        ind_res = supabase.table("industry_monitor")\
            .select("industry, summary").eq("monitor_date", TODAY).execute()
        industry_ctx = "\n".join([
            f"[{r['industry']}] {r['summary'][:100]}"
            for r in (ind_res.data or []) if r.get("summary")
        ]) or "ì‚°ì—…êµ° ë°ì´í„° ì—†ìŒ"
    except:
        industry_ctx = "ì‚°ì—…êµ° ë°ì´í„° ì—†ìŒ"

    initiative_prompts = {
        "KW": (
            f"ì˜¤ëŠ˜ í‚¤ì›Œë“œ ì„±ê³¼:\n{perf_ctx}\n\n"
            f"ì˜¤ëŠ˜ ë‰´ìŠ¤ ì»¨í…ìŠ¤íŠ¸:\n{today_ctx}\n\n"
            f"ì‚°ì—…êµ° ë™í–¥:\n{industry_ctx}\n\n"
            "ìœ„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìœ ì € í‚¤ì›Œë“œë¥¼ ê´€ë¦¬í•˜ë¼.\n"
            "ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ë¼. ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì ˆëŒ€ ê¸ˆì§€:\n"
            "[ADD]ì¶”ê°€ì¶”ì²œí‚¤ì›Œë“œ1,ì¶”ê°€ì¶”ì²œí‚¤ì›Œë“œ2,ì¶”ê°€ì¶”ì²œí‚¤ì›Œë“œ3\n"
            "[REMOVE]ì œê±°ì¶”ì²œí‚¤ì›Œë“œ1,ì œê±°ì¶”ì²œí‚¤ì›Œë“œ2\n"
            "[REASON]ì¶”ê°€/ì œê±° ì´ìœ ë¥¼ ê°ê° í‚¤ì›Œë“œë³„ë¡œ í•œ ì¤„ì”© ì„¤ëª…\n\n"
            "ADD ê¸°ì¤€: ì‚°ì—…êµ° ë™í–¥ì—ì„œ ê¸‰ë¶€ìƒ ì¤‘ì´ê±°ë‚˜ ë‰´ìŠ¤ ë°€ë„ê°€ ë†’ì€ í‚¤ì›Œë“œ\n"
            "REMOVE ê¸°ì¤€: hit_count 3 ì´í•˜ì´ê±°ë‚˜ ì˜¤ëŠ˜ ë‰´ìŠ¤ê°€ ì—†ëŠ” í‚¤ì›Œë“œ"
        ),
        "QA": (
            f"ì˜¤ëŠ˜ ë¸Œë¦¬í•‘ ë°ì´í„°:\n{today_ctx}\n\n"
            "ì˜¤ëŠ˜ ë¦¬í¬íŠ¸ì˜ í’ˆì§ˆì„ 100ì  ë§Œì ìœ¼ë¡œ í‰ê°€í•˜ê³ , "
            "ê°œì„ ì´ í•„ìš”í•œ ì ì„ instruction ì—…ë°ì´íŠ¸ í˜•íƒœë¡œ ì œì•ˆí•˜ë¼. "
            "ì ìˆ˜ì™€ ê·¼ê±°ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•  ê²ƒ. ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(**,## ë“±) ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€."
        ),
        "DATA": (
            f"ì˜¤ëŠ˜ ë‰´ìŠ¤ ìˆ˜ì§‘ ì„±ê³¼:\n{perf_ctx}\n\n"
            "ë‰´ìŠ¤ ìˆ˜ì§‘ëŸ‰ì´ ì ì€ í‚¤ì›Œë“œë‚˜ í’ˆì§ˆ ì´ìŠˆë¥¼ ë¶„ì„í•˜ê³  "
            "ë°ì´í„° ìˆ˜ì§‘ ì „ëµ ê°œì„ ì•ˆì„ instruction ì—…ë°ì´íŠ¸ í˜•íƒœë¡œ ì œì•ˆí•˜ë¼. ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€."
        ),
        "BA": (
            f"ì˜¤ëŠ˜ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸:\n{today_ctx}\n\n"
            "ì˜¤ëŠ˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ì—ì„œ ë¶€ì¡±í–ˆë˜ ì ì„ íŒŒì•…í•˜ê³  "
            "ë” ë‚ ì¹´ë¡œìš´ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ê¸° ìœ„í•œ instruction ê°œì„ ì•ˆì„ ì œì•ˆí•˜ë¼. ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€."
        ),
        "BRIEF": (
            f"ì˜¤ëŠ˜ ë‰´ìŠ¤ ì»¨í…ìŠ¤íŠ¸:\n{today_ctx}\n\n"
            f"ì‚°ì—…êµ° ë™í–¥:\n{industry_ctx}\n\n"
            "ë‹¹ì‹ ì€ ë¶„ì„íŒ€ ë¦¬ë”(BRIEF)ì…ë‹ˆë‹¤. "
            "ì˜¤ëŠ˜ ì „ì²´ ë¶„ì„ í’ˆì§ˆì„ ë¦¬ë” ì‹œê°ìœ¼ë¡œ ìì²´ í‰ê°€í•˜ê³ , "
            "BAÂ·STOCKÂ·PMÂ·HR ê° ë‹´ë‹¹ìì—ê²Œ ë‚´ì¼ ë¶„ì„ ê°œì„ ì„ ìœ„í•œ ì§€ì‹œ ì‚¬í•­ì„ ì œì•ˆí•˜ë¼.\n"
            "í˜•ì‹: [ROLE]ì—­í• ëª… [DIRECTIVE]ì§€ì‹œë‚´ìš© (ê° ì—­í• ë§ˆë‹¤ í•œ ì¤„). ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€."
        ),
        "MASTER": (
            f"ì˜¤ëŠ˜ ì „ì²´ ì‹œìŠ¤í…œ ì„±ê³¼:\ní‚¤ì›Œë“œ ì„±ê³¼:\n{perf_ctx}\n\në‰´ìŠ¤ ì»¨í…ìŠ¤íŠ¸:\n{today_ctx}\n\n"
            "ì „ì²´ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ì˜¤ëŠ˜ ì„±ê³¼ë¥¼ ì¢…í•© í‰ê°€í•˜ê³ , "
            "ê°€ì¥ ì‹œê¸‰í•œ ê°œë°œ ë˜ëŠ” ê°œì„  ì•ˆê±´ 1ê°€ì§€ë¥¼ dev_backlog ë“±ë¡ í˜•íƒœë¡œ ì œì•ˆí•˜ë¼. "
            "ì œì•ˆ í˜•ì‹: [TITLE]ì•ˆê±´ì œëª© [DETAIL]ìƒì„¸ìš”êµ¬ì‚¬í•­. ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(**,## ë“±) ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€."
        ),
    }

    for role, prompt in initiative_prompts.items():
        agent_info = agents.get(role)
        if not agent_info:
            continue
        try:
            print(f"  ğŸ¤– [{role}] ììœ¨ ë°œì˜ ìƒì„± ì¤‘...")
            proposal = call_agent(prompt, agent_info, force_one_line=False)

            if not proposal or proposal in ["ë¶„ì„ ì§€ì—° ì¤‘", "ë¶„ì„ ë°ì´í„° ì—†ìŒ"]:
                print(f"  âš ï¸ [{role}] ë°œì˜ ë‚´ìš© ì—†ìŒ â€” ìŠ¤í‚µ")
                continue

            if role == "KW":
                add_m    = re.search(r"\[ADD\](.*?)(?=\[REMOVE\]|\[REASON\]|$)",    proposal, re.DOTALL)
                remove_m = re.search(r"\[REMOVE\](.*?)(?=\[ADD\]|\[REASON\]|$)",    proposal, re.DOTALL)
                reason_m = re.search(r"\[REASON\](.*?)$",                            proposal, re.DOTALL)

                add_kws    = [k.strip() for k in (add_m.group(1).split(",") if add_m else []) if k.strip()]
                remove_kws = [k.strip() for k in (remove_m.group(1).split(",") if remove_m else []) if k.strip()]
                reason     = reason_m.group(1).strip() if reason_m else "KW ì—ì´ì „íŠ¸ ììœ¨ ë¶„ì„"

                if not add_kws and not remove_kws:
                    print(f"  âš ï¸ [KW] íŒŒì‹± ì‹¤íŒ¨ â€” ì›ë¬¸ ë“±ë¡")
                    supabase.table("pending_approvals").insert({
                        "agent_role":           "KW",
                        "proposed_instruction": strip_markdown(proposal),
                        "proposal_reason":      f"{TODAY} KW ììœ¨ ë°œì˜ (íŒŒì‹± ì‹¤íŒ¨)",
                        "needs_dev":            False,
                        "status":               "PENDING",
                    }).execute()
                    continue

                structured = (
                    f"[í‚¤ì›Œë“œ ê´€ë¦¬ ì œì•ˆ]\n"
                    f"ì¶”ê°€ ì¶”ì²œ: {', '.join(add_kws) if add_kws else 'ì—†ìŒ'}\n"
                    f"ì œê±° ì¶”ì²œ: {', '.join(remove_kws) if remove_kws else 'ì—†ìŒ'}\n\n"
                    f"[ê·¼ê±°]\n{strip_markdown(reason)}"
                )
                supabase.table("pending_approvals").insert({
                    "agent_role":           "KW",
                    "proposed_instruction": structured,
                    "proposal_reason":      f"{TODAY} í‚¤ì›Œë“œ ì¶”ê°€/ì œê±° ì œì•ˆ â€” ì¶”ê°€ {len(add_kws)}ê°œ / ì œê±° {len(remove_kws)}ê°œ",
                    "needs_dev":            False,
                    "status":               "PENDING",
                }).execute()
                print(f"  âœ… [KW] í‚¤ì›Œë“œ ì œì•ˆ ë“±ë¡ ì™„ë£Œ â€” ì¶”ê°€ {len(add_kws)}ê°œ / ì œê±° {len(remove_kws)}ê°œ")
                continue

            if role == "MASTER":
                t = re.search(r"\[TITLE\](.*?)(?=\[DETAIL\]|$)",  proposal, re.DOTALL)
                d = re.search(r"\[DETAIL\](.*?)$",                 proposal, re.DOTALL)
                if t and d:
                    title  = strip_markdown(t.group(1).strip()).split('\n')[0]
                    detail = strip_markdown(d.group(1).strip())
                    supabase.table("dev_backlog").insert({
                        "title":         f"[AIë°œì˜] {title}",
                        "task_detail":   detail,
                        "affected_file": "news_bot.py",
                        "priority":      5,
                        "status":        "PENDING",
                    }).execute()
                    print(f"  ğŸ“‹ [MASTER] dev_backlog ìë™ ë“±ë¡: {title}")
                continue

            if role == "BRIEF":
                supabase.table("pending_approvals").insert({
                    "agent_role":           "BRIEF",
                    "proposed_instruction": strip_markdown(proposal),
                    "proposal_reason":      f"{TODAY} BRIEF ë¦¬ë” ììœ¨ ë°œì˜ â€” ì§ì› ì§€ì‹œ ì‚¬í•­",
                    "needs_dev":            False,
                    "status":               "PENDING",
                }).execute()
                print(f"  âœ… [BRIEF] ììœ¨ ë°œì˜ ë“±ë¡ ì™„ë£Œ")
                continue

            supabase.table("pending_approvals").insert({
                "agent_role":           role,
                "proposed_instruction": strip_markdown(proposal),
                "proposal_reason":      f"{TODAY} ë¸Œë¦¬í•‘ ë°ì´í„° ê¸°ë°˜ ììœ¨ ë°œì˜",
                "needs_dev":            False,
                "status":               "PENDING",
            }).execute()
            print(f"  âœ… [{role}] ììœ¨ ë°œì˜ ë“±ë¡ ì™„ë£Œ â†’ HQ ê²°ì¬ ëŒ€ê¸°")

        except Exception as e:
            print(f"  âŒ [{role}] ììœ¨ ë°œì˜ ì‹¤íŒ¨: {e}")

    print("\nğŸ¢ [BRIEFâ†’HR] ì—ì´ì „íŠ¸ ì¡°ì§ êµ¬ì„± íŒŒì´í”„ë¼ì¸ ì‹œì‘...")
    try:
        run_brief_hr_org_pipeline(agents, today_ctx, industry_ctx)
    except Exception as e:
        print(f"  âŒ [BRIEFâ†’HR] íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
    print("ğŸ¢ [BRIEFâ†’HR] íŒŒì´í”„ë¼ì¸ ì™„ë£Œ\n")

    print("ğŸ§  [Initiative] ììœ¨ ë°œì˜ ì™„ë£Œ â€” HQì—ì„œ í™•ì¸í•˜ì„¸ìš”")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    import argparse
    import sys
    
    parser = argparse.ArgumentParser(description="Fitz News Bot - Sovereign Intelligence System")
    parser.add_argument('--mode', type=str, default='',
                        help='ì‹¤í–‰ ëª¨ë“œ: dev, BRIEFING, INDUSTRY, GOVERNANCE')
    parser.add_argument('--backlog-id', type=str, default='',
                        help='ê°œë°œ ë°±ë¡œê·¸ ID (--mode dev ì‚¬ìš© ì‹œ)')
    
    args = parser.parse_args()
    
    # ëª…ë ¹ì¤„ ì¸ìë¡œ ëª¨ë“œ ì§€ì •ëœ ê²½ìš°
    if args.mode:
        mode = args.mode.upper()
        
        if mode == 'DEV':
            # DEV ë°°í¬ ëª¨ë“œ: íŠ¹ì • ë°±ë¡œê·¸ ID ì²˜ë¦¬
            backlog_id = args.backlog_id or os.environ.get("BACKLOG_ID", "")
            if not backlog_id:
                print("âŒ [DEV] backlog_idê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                sys.exit(1)
            
            print(f"ğŸ› ï¸ [DEV] ê°œë°œ ë°°í¬ ëª¨ë“œ ì‹¤í–‰: backlog_id={backlog_id}")
            run_self_evolution(backlog_id)
            sys.exit(0)
            
        elif mode == 'GOVERNANCE':
            print("ğŸŒ™ [GOVERNANCE] 23:30 ë§ˆê° ì‘ì—… ëª¨ë“œ")
            manage_deadline_approvals()
            sys.exit(0)
            
        elif mode == 'INDUSTRY':
            print("ğŸ­ [INDUSTRY] 06:00 ì‚°ì—…êµ° ëª¨ë‹ˆí„°ë§ ëª¨ë“œ")
            run_industry_monitor()
            sys.exit(0)
            
        elif mode == 'BRIEFING':
            print("â˜€ï¸ [BRIEFING] 09:00 ì •ê¸° ë¸Œë¦¬í•‘ ëª¨ë“œ")
            manage_deadline_approvals()
            run_autonomous_engine()
            sync_data_to_github()
            sys.exit(0)
        else:
            print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë“œ: {mode}")
            sys.exit(1)
    
    # í™˜ê²½ ë³€ìˆ˜ë¡œ ëª¨ë“œ ì§€ì • (ê¸°ì¡´ ë°©ì‹ í˜¸í™˜)
    cron_type = os.environ.get("CRON_TYPE", "BRIEFING").upper()
    
    if cron_type == "GOVERNANCE":
        print("ğŸŒ™ [GOVERNANCE] 23:30 ë§ˆê° ì‘ì—… ëª¨ë“œ")
        manage_deadline_approvals()
    elif cron_type == "INDUSTRY":
        print("ğŸ­ [INDUSTRY] 06:00 ì‚°ì—…êµ° ëª¨ë‹ˆí„°ë§ ëª¨ë“œ")
        run_industry_monitor()
    else:
        print("â˜€ï¸ [BRIEFING] 09:00 ì •ê¸° ë¸Œë¦¬í•‘ ëª¨ë“œ")
        manage_deadline_approvals()
        run_autonomous_engine()
        sync_data_to_github()
